{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d6fbf84",
   "metadata": {
    "papermill": {
     "duration": 0.012513,
     "end_time": "2023-02-27T12:41:16.921392",
     "exception": false,
     "start_time": "2023-02-27T12:41:16.908879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding:20px;color:white;margin:0;font-size:24px;text-align:left;display:fill;border-radius:5px;background-color:#3A578A;overflow:hidden\">Things to Know</div>\n",
    "\n",
    "## <span style=\"color: #3A578A;\">Convert a column from `float32` to `float16`. What does happen?</span>\n",
    "\n",
    "\n",
    "When we convert a column from `float32 `to `float16`, we **decrease the number of unique values** because `float16` **uses fewer bits to represent a number** compared to `float32`. Specifically, `float32` uses 32 bits to represent a number, while `float16` uses only 16 bits.\n",
    "\n",
    "In a `float32` column, the number of unique values that can be represented is `2^32`, which is approximately 4.3 billion. This is a very large number, and it allows for a high degree of precision in representing decimal values.\n",
    "\n",
    "However, in a `float16` column, the number of unique values that can be represented is `2^16`, which is approximately 65,000. This is a **much smaller number compared to `float32`**, and it means that **the precision of the decimal values that can be represented is lower.**\n",
    "\n",
    "When we convert a `float32` column to a `float16` column, some of the unique values in the original column will not be representable in the new column. These values will be rounded to the nearest representable value in the `float16` format, resulting in a decrease in the number of unique values. **This decrease in the number of unique values can have an impact on the accuracy of the data, especially if the data has a wide range of values or if the values are very close to each other.**\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "**Why when we convert a column from `float32` to `float16` do we lose information?**\n",
    "\n",
    "In `float32`, 32 bits are used to represent a number, with 23 bits used for the mantissa (fractional part) and 8 bits used for the exponent (the power of 2 that the mantissa is multiplied by). This allows for a wide range of values to be represented with high precision, **making `float32 `suitable for scientific and engineering applications where accuracy is important.**\n",
    "\n",
    "However, in `float16`, only 16 bits are used to represent a number, with 10 bits used for the mantissa and 5 bits used for the exponent. **This means that `float16` can represent a smaller range of values with less precision compared to `float32`.**\n",
    "\n",
    "When we convert a `float32` column to a `float16` column, **some of the information may be lost because the number of bits used to represent each value has been reduced.** Specifically, the mantissa and exponent **values in `float32` may need to be rounded or truncated to fit into the smaller number of bits available in `float16`.** This can result in a loss of precision or a rounding error, which may affect the accuracy of the data.\n",
    "\n",
    "In addition, **some operations on `float16` numbers may result in overflow or underflow errors because the range of values that can be represented is smaller.** For example, if a `float16 `number is multiplied by a large value, the result may exceed the maximum value that can be represented, resulting in an overflow error. **These types of errors can also contribute to the loss of information when converting from `float32` to `float16`.**\n",
    "\n",
    "## <span style=\"color: #3A578A;\">Money has this unique property that values although highly cardinal it is still discrete with an increment of 0.01 USD.</span>\n",
    "\n",
    "The term “high cardinality” means that there can be many possible values for a single attribute.\n",
    "\n",
    "Money has the unique property that its values are highly cardinal, meaning that there are a large number of distinct possible values, but it is still discrete with an increment of 0.01USD.\n",
    "\n",
    "What this means is that there are a finite number of possible values that can be represented in the currency system, and **each value is separated from the next by a fixed increment of 0.01USD**. For example, in the United States currency system, the smallest unit is the penny, which is worth 0.01USD. This means that any amount of money can be represented as a combination of a whole number of dollars and a fractional amount in cents, with each cent representing a discrete unit of value.\n",
    "\n",
    "This discrete nature of money with a fixed increment of 0.01USD is important for many financial calculations and transactions, such as calculating interest, rounding amounts, and making change. It also means that when working with money, it is often necessary to round values to the nearest cent, which can introduce rounding errors.\n",
    "\n",
    "## <span style=\"color: #3A578A;\">What is a uniform distribution ?</span>\n",
    "\n",
    "A **uniform distribution** is a type of probability distribution in which **all possible values within a given range are equally likely to occur**. In other words, the probability density function (PDF) of a uniform distribution is constant over a specified range of values.\n",
    "\n",
    "For example, if we consider a uniform distribution between 0 and 1, any value between 0 and 1 is equally likely to occur. The PDF for this distribution is a horizontal line at a height of 1, between 0 and 1, and 0 elsewhere. The cumulative distribution function (CDF) for a uniform distribution is a straight line that increases linearly from 0 to 1 over the specified range of values.\n",
    "\n",
    "A uniform distribution, **sometimes also known as a rectangular distribution, is a distribution that has constant probability.**\n",
    "\n",
    "<img width=\"926\" alt=\"image\" src=\"https://user-images.githubusercontent.com/28102493/220114129-7896bb12-1d53-49a7-8144-af4dc1637e61.png\">\n",
    "\n",
    "Uniform distributions are often used as models for situations in which there is no a priori reason to expect one value to be more likely than any other value within the range. For example, if we were randomly selecting a number between 1 and 10, and had no reason to expect any particular value to be more likely than any other, we might use a uniform distribution to model the probability of selecting each value.\n",
    "\n",
    "Uniform distributions are also commonly used in computer simulations and in generating random numbers for various applications, such as in cryptography, gambling, and scientific experiments. They are often generated using pseudo-random number generators, which are algorithms that generate a sequence of random numbers that appear to be random, but are actually determined by a starting value known as a seed.\n",
    "\n",
    "A **random uniform value** refers to a value that is generated randomly from a uniform distribution.\n",
    "\n",
    "A random value generated from a uniform distribution has the same probability of being any value within the specified range. For example, if we generate a random uniform value between 0 and 1, any value between 0 and 1 is equally likely to be generated. This means that the probability of generating a value between 0.1 and 0.2 is the same as the probability of generating a value between 0.8 and 0.9.\n",
    "\n",
    "## <span style=\"color: #3A578A;\">What is a random uniform noise?</span>\n",
    "Random uniform noise is a type of noise that is added to data in a random way, such that each value added is drawn from a uniform distribution. A uniform distribution is a probability distribution where every value in a given range is equally likely to occur.\n",
    "\n",
    "In the context of machine learning, random uniform noise can be added to data **as a form of regularization or to introduce randomness into the learning process.** This can help **prevent overfitting and improve the generalization ability of the model.** For example, if we are training a model to recognize images of cats and dogs, we might add random uniform noise to the training images to simulate small variations in the images, such as changes in lighting or minor distortions. This can help the model learn to recognize cats and dogs in a more robust way, rather than simply memorizing specific examples from the training data.\n",
    "\n",
    "Random uniform noise **can also be used to generate synthetic data for training models, or to simulate noise in real-world data.** In general, adding random uniform noise can help make machine learning models more flexible and robust to different sources of variation and noise in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a606df",
   "metadata": {
    "papermill": {
     "duration": 0.010779,
     "end_time": "2023-02-27T12:41:16.943450",
     "exception": false,
     "start_time": "2023-02-27T12:41:16.932671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding:20px;color:white;margin:0;font-size:24px;text-align:left;display:fill;border-radius:5px;background-color:#3A578A;overflow:hidden\">Available Datasets</div>\n",
    "\n",
    "1. [AMEX data - integer dtypes - parquet format](https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format): Post processed dataset to transform float data types to int data types where it can be done, by raddar with the discuassion [here](https://www.kaggle.com/competitions/amex-default-prediction/discussion/328514)\n",
    "\n",
    "1. [AMEX-Feather-Dataset](https://www.kaggle.com/datasets/munumbutt/amexfeather): In this Feather file, the floating point precision has been reduced from 64 bit to 16 bit, compressed version of the train and test sets.\n",
    "\n",
    "1. [Amex Competition Data in Parquet Format\n",
    "](https://www.kaggle.com/datasets/odins0n/amex-parquet): American Express - Default Prediction Competition Data in Parquet Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe3374",
   "metadata": {
    "papermill": {
     "duration": 0.010766,
     "end_time": "2023-02-27T12:41:16.965369",
     "exception": false,
     "start_time": "2023-02-27T12:41:16.954603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding:20px;color:white;margin:0;font-size:24px;text-align:left;display:fill;border-radius:5px;background-color:#3A578A;overflow:hidden\">Data Loading</div>\n",
    "\n",
    "## <span style=\"color: #3A578A;\">Python Garbage Collection</span>\n",
    "\n",
    "In Python, `gc.collect()` is a function provided by the gc module which **forces garbage collection, i.e., it frees up memory that is no longer needed by the program.**\n",
    "\n",
    "Python's garbage collector automatically deallocates memory that is no longer being used by the program. However, this automatic garbage collection may not always happen immediately, as it can depend on various factors such as the amount of memory available or the workload of the system. In some cases, the automatic garbage collection may not free up memory as quickly as needed, leading to memory leaks and other issues.\n",
    "\n",
    "Calling `gc.collect()` manually **forces the garbage collector to run immediately, which can help free up memory that is no longer needed by the program.** This can be particularly useful in situations where memory usage is a concern, such as when working with large datasets or when running long-running processes.\n",
    "\n",
    "It's worth noting that calling gc.collect() too frequently or at inappropriate times can actually slow down your program's performance, so it should be used judiciously and only when necessary.\n",
    "\n",
    "In general, deleting a DataFrame with the `del` command in a Jupyter notebook will remove the variable reference to the DataFrame and free up memory, as long as there are no other references to the DataFrame.\n",
    "\n",
    "Python's garbage collector will eventually clean up any memory that is no longer being used by the program, including the memory previously used by the DataFrame. **However, calling gc.collect() manually may speed up the garbage collection process and free up memory more quickly.**\n",
    "\n",
    "**That being said, in most cases, it is not necessary to call gc.collect() manually after deleting a DataFrame with del, as the garbage collector should eventually clean up any unused memory. However, in cases where you are working with very large datasets or running long-running processes, calling gc.collect() manually may be useful to free up memory more quickly.**\n",
    "\n",
    "\n",
    "## <span style=\"color: #3A578A;\">Rapids</span>\n",
    "\n",
    "RAPIDS is a suite of open-source software libraries and APIs developed by NVIDIA that allows users to **execute end-to-end data science and analytics pipelines entirely on GPUs.** The RAPIDS suite includes libraries for data preparation, machine learning, graph analytics, and visualization, and is designed to enable faster and more efficient data processing and analysis.It relies on **NVIDIA® CUDA®** primitives for low-level compute optimization but exposes that GPU parallelism and high-bandwidth memory speed through **user-friendly Python interfaces.**\n",
    "\n",
    "One of the key advantages of RAPIDS is that it leverages the power of GPUs to accelerate data processing and analysis. GPUs are highly parallel processors that can perform many calculations simultaneously, making them well-suited for data-intensive tasks such as machine learning and data visualization. By running data science and analytics pipelines entirely on GPUs, RAPIDS can dramatically reduce the time required to process and analyze large datasets.\n",
    "\n",
    "**Another advantage of RAPIDS is that it integrates seamlessly with popular data science tools and frameworks, such as Python, Jupyter, and scikit-learn.** This makes it easy for users to incorporate RAPIDS into their existing data science workflows and take advantage of its powerful capabilities without having to learn new tools or programming languages. RAPIDS is designed to look and feel like Python and offers a collection of libraries for running a data science pipeline completely through GPUs. RAPIDS includes a Dataframe API, which integrates with machine learning algorithms.\n",
    "\n",
    "\n",
    "Overall, RAPIDS is a powerful tool for data scientists and analysts who need to process and analyze large datasets quickly and efficiently. By leveraging the power of GPUs, RAPIDS can help accelerate the pace of data-driven discovery and enable new insights that would be difficult or impossible to achieve using traditional CPU-based approaches.\n",
    "\n",
    "In order to use RAPIDS, you will need a machine with a compatible NVIDIA GPU. This is because RAPIDS is designed to run entirely on GPUs, leveraging their high parallelism and computational power to accelerate data processing and analysis.\n",
    "\n",
    "However, not all NVIDIA GPUs are compatible with RAPIDS, and the specific requirements will depend on the library or tool you are using within the RAPIDS suite. For example, some libraries may require a GPU with a minimum amount of memory, or a specific version of the CUDA Toolkit (NVIDIA's parallel computing platform and programming model).\n",
    "\n",
    "Before using RAPIDS, it's important to check the system requirements for the specific library or tool you plan to use, and ensure that your machine meets these requirements. Additionally, if you plan to use RAPIDS in a distributed computing environment, you may need to set up a cluster of machines with compatible GPUs to run your workflows.\n",
    "\n",
    "<img width=\"1476\" alt=\"image\" src=\"https://user-images.githubusercontent.com/28102493/220171678-545b471a-5866-47c7-bcf1-300eb1c7678d.png\">\n",
    "\n",
    "Read more about RAPIDS here. The RAPIDS libraries allow us to perform all our data science on GPUs including reading data, transforming data, modeling, validation, and prediction. The package cuDF provides Pandas functionality and cuML provides Scikit-learn functionality. Other packages provide additional tools.\n",
    "\n",
    "Since GPUs are faster than CPUs, we save time, save money, and can increase model accuracy by performing additional tasks like hyperparameter searches, feature engineering and selection, data augmentation, and ensembling with bagging and boosting.\n",
    "\n",
    "\n",
    "\n",
    "- **`cuDF`** is a GPU DataFrame library that provides a pandas-like API for loading, filtering, and manipulating data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f9d80b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:41:16.991597Z",
     "iopub.status.busy": "2023-02-27T12:41:16.990724Z",
     "iopub.status.idle": "2023-02-27T12:41:17.506048Z",
     "shell.execute_reply": "2023-02-27T12:41:17.504753Z"
    },
    "papermill": {
     "duration": 0.532673,
     "end_time": "2023-02-27T12:41:17.509241",
     "exception": false,
     "start_time": "2023-02-27T12:41:16.976568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate\n",
    "import scipy.integrate\n",
    "#import cuDF # Normally, it worked out of the box with the GPU P100 on and Environment = Always use latest environment\n",
    "# but the last two days it doesn't work and I'm getting the error : \"ModuleNotFoundError: No module named 'cuDF'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dffdf429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:41:17.534891Z",
     "iopub.status.busy": "2023-02-27T12:41:17.533679Z",
     "iopub.status.idle": "2023-02-27T12:41:17.541094Z",
     "shell.execute_reply": "2023-02-27T12:41:17.540069Z"
    },
    "papermill": {
     "duration": 0.02335,
     "end_time": "2023-02-27T12:41:17.543781",
     "exception": false,
     "start_time": "2023-02-27T12:41:17.520431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(data_path: str, usecols: [] = None):\n",
    "    if usecols is not None: \n",
    "        df = pd.read_parquet(data_path, columns=usecols)\n",
    "    else: \n",
    "        df = pd.read_parquet(data_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1b2121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:41:17.569155Z",
     "iopub.status.busy": "2023-02-27T12:41:17.567913Z",
     "iopub.status.idle": "2023-02-27T12:41:46.060146Z",
     "shell.execute_reply": "2023-02-27T12:41:46.059160Z"
    },
    "papermill": {
     "duration": 28.507676,
     "end_time": "2023-02-27T12:41:46.062927",
     "exception": false,
     "start_time": "2023-02-27T12:41:17.555251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = load_data(data_path=\"../input/amex-data-integer-dtypes-parquet-format/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0950e8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:41:46.088011Z",
     "iopub.status.busy": "2023-02-27T12:41:46.086654Z",
     "iopub.status.idle": "2023-02-27T12:41:46.096078Z",
     "shell.execute_reply": "2023-02-27T12:41:46.094747Z"
    },
    "papermill": {
     "duration": 0.024569,
     "end_time": "2023-02-27T12:41:46.098740",
     "exception": false,
     "start_time": "2023-02-27T12:41:46.074171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5531451, 190)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b773b6cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:41:46.123579Z",
     "iopub.status.busy": "2023-02-27T12:41:46.122619Z",
     "iopub.status.idle": "2023-02-27T12:41:46.165538Z",
     "shell.execute_reply": "2023-02-27T12:41:46.164324Z"
    },
    "papermill": {
     "duration": 0.058001,
     "end_time": "2023-02-27T12:41:46.168029",
     "exception": false,
     "start_time": "2023-02-27T12:41:46.110028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>1.000653</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.954180</td>\n",
       "      <td>3</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>1.002700</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.117169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>0.947248</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.000727</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.117325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2       P_2  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-03-09  0.938469   \n",
       "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-04-07  0.936665   \n",
       "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-05-28  0.954180   \n",
       "3  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-06-13  0.960384   \n",
       "4  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-07-16  0.947248   \n",
       "\n",
       "   D_39       B_1       B_2       R_1       S_3  D_41       B_3  ...  D_136  \\\n",
       "0     0  0.008724  1.006838  0.009228  0.124035   0.0  0.004709  ...     -1   \n",
       "1     0  0.004923  1.000653  0.006151  0.126750   0.0  0.002714  ...     -1   \n",
       "2     3  0.021655  1.009672  0.006815  0.123977   0.0  0.009423  ...     -1   \n",
       "3     0  0.013683  1.002700  0.001373  0.117169   0.0  0.005531  ...     -1   \n",
       "4     0  0.015193  1.000727  0.007605  0.117325   0.0  0.009312  ...     -1   \n",
       "\n",
       "   D_137  D_138  D_139  D_140  D_141  D_142  D_143     D_144  D_145  \n",
       "0     -1     -1      0      0    0.0    NaN      0  0.000610      0  \n",
       "1     -1     -1      0      0    0.0    NaN      0  0.005492      0  \n",
       "2     -1     -1      0      0    0.0    NaN      0  0.006986      0  \n",
       "3     -1     -1      0      0    0.0    NaN      0  0.006527      0  \n",
       "4     -1     -1      0      0    0.0    NaN      0  0.008126      0  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e68c769f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:41:46.193503Z",
     "iopub.status.busy": "2023-02-27T12:41:46.193101Z",
     "iopub.status.idle": "2023-02-27T12:41:47.355893Z",
     "shell.execute_reply": "2023-02-27T12:41:47.354534Z"
    },
    "papermill": {
     "duration": 1.178945,
     "end_time": "2023-02-27T12:41:47.358733",
     "exception": false,
     "start_time": "2023-02-27T12:41:46.179788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5531451 entries, 0 to 5531450\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: float32(93), int16(9), int8(86), object(2)\n",
      "memory usage: 3.4 GB\n"
     ]
    }
   ],
   "source": [
    "train_data.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd1dc46",
   "metadata": {
    "papermill": {
     "duration": 0.011549,
     "end_time": "2023-02-27T12:41:47.382610",
     "exception": false,
     "start_time": "2023-02-27T12:41:47.371061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# <div style=\"padding:20px;color:white;margin:0;font-size:24px;text-align:left;display:fill;border-radius:5px;background-color:#3A578A;overflow:hidden\">Feature Engineering</div>\n",
    "\n",
    "We can create the following groups of features:\n",
    "\n",
    "## <span style=\"color: #3A578A;\">Features aggregated by time period</span>\n",
    "\n",
    "min, max, mean, std for the last 3 and last 6 months\n",
    "\n",
    "1. Selected **features averaged over all statements** of a customer \n",
    "1. The **minimum or maximum of selected features** over all statements of a customer \n",
    "1. Selected features taken from the **last statement** of a customer \n",
    "1. **First:** Just like the last feature, but first.\n",
    "\n",
    "On this competition we get information about clients of AMEX over time. Most high scoring notebooks on this competiion focused on aggregating the information per client and create a single row of extracted features: One for each client.\n",
    "\n",
    "One of such agg function is last.\n",
    "\n",
    "Quick examination revealed that the last feature is extreamly powerful at predicting if the client defaults or not (well.. make sense..). So I took this two steps further ..... Lag Features\n",
    "\n",
    "\n",
    "## <span style=\"color: #3A578A;\">Lag features</span>\n",
    "\n",
    "Introduction to feature engineering for time series forecasting\n",
    "\n",
    "Lag features are values at prior timesteps that are considered useful because they are created on the assumption that what happened in the past can influence or contain a sort of intrinsic information about the future. Lag features are features that capture the behavior of a target variable (such as a time series) at different time points in the past. They are commonly used in time series analysis and forecasting, as they can help capture patterns in the data over time.\n",
    "\n",
    "To create a lag feature, you simply **shift** the target variable forward in time by a certain number of time steps (referred to as the lag time), and use the resulting values as input features for your predictive model. For example, suppose you are working with daily stock price data and want to predict tomorrow's closing price based on past price data. You could create lag features that capture the closing price from the past 1, 5, and 10 days, and use these values as input features for your predictive model.\n",
    "\n",
    "In addition to capturing patterns in the data over time, lag features can also help account for autocorrelation in the data. **Autocorrelation refers to the tendency for a time series to be correlated with its own past values. By incorporating lag features into your predictive model, you can help capture this autocorrelation and improve the accuracy of your predictions.**\n",
    "\n",
    "It's important to note that when creating lag features, you should be careful not to include future information in your model. For example, if you are trying to predict tomorrow's stock price, you cannot use information from tomorrow or beyond in your model. Additionally, the appropriate lag time period will depend on the specific problem you are working on and the nature of the data.\n",
    "\n",
    "\"Lag\" fearures can capture the change over time about each client I calculated two features for every first, last pair:\n",
    "\n",
    "\n",
    "1. **First / Last interactions:** (Last - First) and (Last / First)\n",
    "    1. Last - First: The change since we first see the client to the last time we see the client.\n",
    "    1. Last / First: The fractional difference since we first see the client to the last time we see the client.\n",
    "1. The **difference between last value and the average** (this features gives a nice boost)  \n",
    "1. The **difference between last value and the lag1**\n",
    "\n",
    "## <span style=\"color: #3A578A;\">Null count features</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6144db43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:41:47.409085Z",
     "iopub.status.busy": "2023-02-27T12:41:47.407928Z",
     "iopub.status.idle": "2023-02-27T12:41:47.422772Z",
     "shell.execute_reply": "2023-02-27T12:41:47.421388Z"
    },
    "papermill": {
     "duration": 0.031066,
     "end_time": "2023-02-27T12:41:47.425592",
     "exception": false,
     "start_time": "2023-02-27T12:41:47.394526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineer(df: pd.DataFrame, labels: pd.DataFrame = None):\n",
    "    \n",
    "    # We keep all the features except for customer_ID and the date\n",
    "    features = df.drop([\"customer_ID\", \"S_2\"], axis = 1).columns.to_list()\n",
    "    # As described in the data tab in the competition description\n",
    "    cat_features = [\n",
    "        \"B_30\",\n",
    "        \"B_38\",\n",
    "        \"D_114\",\n",
    "        \"D_116\",\n",
    "        \"D_117\",\n",
    "        \"D_120\",\n",
    "        \"D_126\",\n",
    "        \"D_63\",\n",
    "        \"D_64\",\n",
    "        \"D_66\",\n",
    "        \"D_68\",\n",
    "    ]\n",
    "    # The rest of the features - columns are numerical features\n",
    "    num_features = [col for col in features if col not in cat_features]\n",
    "    \n",
    "    print(\"Starting feature engineer on numerical features...\")\n",
    "    # Numerical features aggregated by time period\n",
    "    df_num_agg = df.groupby(\"customer_ID\")[num_features].agg([\"mean\", \"std\", \"min\", \"max\", \"first\", \"last\"])\n",
    "    df_num_agg.columns = [\"_\".join(x) for x in df_num_agg.columns]\n",
    "    df_num_agg.reset_index(inplace = True)\n",
    "    \n",
    "    print(\"Starting feature engineer on lag features...\")\n",
    "    # Lag Features: First / Last interactions\n",
    "    for col in df_num_agg.columns:\n",
    "        if 'last' in col and col.replace('last', 'first') in df_num_agg.columns:\n",
    "            \n",
    "            df_num_agg[col + \"_lag_sub\"] = df_num_agg[col] - df_num_agg[col.replace(\"last\", \"first\")]\n",
    "            df_num_agg[col + \"_lag_div\"] = df_num_agg[col] / df_num_agg[col.replace(\"last\", \"first\")]\n",
    "\n",
    "    print(\"Starting feature engineer on categorical features...\")\n",
    "    # Categorical features aggregated by time period\n",
    "    df_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg([\"count\", \"first\", \"last\", \"nunique\"])\n",
    "    df_cat_agg.columns = [\"_\".join(x) for x in df_cat_agg.columns]\n",
    "    df_cat_agg.reset_index(inplace = True)\n",
    "    \n",
    "    if labels is not None: \n",
    "        df_agg = df_num_agg.merge(df_cat_agg, how = \"inner\", on = \"customer_ID\").merge(labels, how = 'inner', on = 'customer_ID')\n",
    "    else:\n",
    "        df_agg = df_num_agg.merge(df_cat_agg, how = \"inner\", on = \"customer_ID\")\n",
    "    del df_num_agg, df_cat_agg\n",
    "\n",
    "    print(\"Dimensions after engineering\", df_agg.shape )\n",
    "    \n",
    "    return df_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d64fe305",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:41:47.451253Z",
     "iopub.status.busy": "2023-02-27T12:41:47.450820Z",
     "iopub.status.idle": "2023-02-27T12:41:48.735221Z",
     "shell.execute_reply": "2023-02-27T12:41:48.733788Z"
    },
    "papermill": {
     "duration": 1.300913,
     "end_time": "2023-02-27T12:41:48.738382",
     "exception": false,
     "start_time": "2023-02-27T12:41:47.437469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"../input/amex-default-prediction/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5538d00f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:41:48.765132Z",
     "iopub.status.busy": "2023-02-27T12:41:48.764056Z",
     "iopub.status.idle": "2023-02-27T12:41:48.771372Z",
     "shell.execute_reply": "2023-02-27T12:41:48.770475Z"
    },
    "papermill": {
     "duration": 0.022924,
     "end_time": "2023-02-27T12:41:48.773528",
     "exception": false,
     "start_time": "2023-02-27T12:41:48.750604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "808d1398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:41:48.799836Z",
     "iopub.status.busy": "2023-02-27T12:41:48.798652Z",
     "iopub.status.idle": "2023-02-27T12:41:48.812166Z",
     "shell.execute_reply": "2023-02-27T12:41:48.810817Z"
    },
    "papermill": {
     "duration": 0.029087,
     "end_time": "2023-02-27T12:41:48.814591",
     "exception": false,
     "start_time": "2023-02-27T12:41:48.785504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.741066\n",
       "1    0.258934\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[\"target\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b5d6d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:41:48.841809Z",
     "iopub.status.busy": "2023-02-27T12:41:48.840412Z",
     "iopub.status.idle": "2023-02-27T12:41:48.855187Z",
     "shell.execute_reply": "2023-02-27T12:41:48.852999Z"
    },
    "papermill": {
     "duration": 0.031706,
     "end_time": "2023-02-27T12:41:48.858409",
     "exception": false,
     "start_time": "2023-02-27T12:41:48.826703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    340085\n",
       "1    118828\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "473c61dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:41:48.886911Z",
     "iopub.status.busy": "2023-02-27T12:41:48.885640Z",
     "iopub.status.idle": "2023-02-27T12:45:37.948447Z",
     "shell.execute_reply": "2023-02-27T12:45:37.947171Z"
    },
    "papermill": {
     "duration": 229.091007,
     "end_time": "2023-02-27T12:45:37.962817",
     "exception": false,
     "start_time": "2023-02-27T12:41:48.871810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature engineer on numerical features...\n",
      "Starting feature engineer on lag features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature engineer on categorical features...\n",
      "Dimensions after engineering (458913, 1462)\n"
     ]
    }
   ],
   "source": [
    "train_df = feature_engineer(train_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06986675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:37.990199Z",
     "iopub.status.busy": "2023-02-27T12:45:37.989713Z",
     "iopub.status.idle": "2023-02-27T12:45:37.996483Z",
     "shell.execute_reply": "2023-02-27T12:45:37.995400Z"
    },
    "papermill": {
     "duration": 0.023486,
     "end_time": "2023-02-27T12:45:37.998758",
     "exception": false,
     "start_time": "2023-02-27T12:45:37.975272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458913, 1462)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "febe98ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.026698Z",
     "iopub.status.busy": "2023-02-27T12:45:38.026045Z",
     "iopub.status.idle": "2023-02-27T12:45:38.034543Z",
     "shell.execute_reply": "2023-02-27T12:45:38.033343Z"
    },
    "papermill": {
     "duration": 0.025575,
     "end_time": "2023-02-27T12:45:38.037333",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.011758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.target = train_df.target.astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8ba6ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.064837Z",
     "iopub.status.busy": "2023-02-27T12:45:38.064367Z",
     "iopub.status.idle": "2023-02-27T12:45:38.202974Z",
     "shell.execute_reply": "2023-02-27T12:45:38.201579Z"
    },
    "papermill": {
     "duration": 0.155729,
     "end_time": "2023-02-27T12:45:38.205636",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.049907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CLEAN RAM\n",
    "del train_data\n",
    "del labels\n",
    "# callgarbage collection,to manage a performance-intensive section of\n",
    "# our program that generates many temporary objects.\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed1d2f",
   "metadata": {
    "papermill": {
     "duration": 0.012035,
     "end_time": "2023-02-27T12:45:38.230247",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.218212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding:20px;color:white;margin:0;font-size:24px;text-align:left;display:fill;border-radius:5px;background-color:#3A578A;overflow:hidden\">Dealing with Imbalanced Dataset</div>\n",
    "\n",
    "## <span style=\"color: #3A578A;\">Note that the negative class has been subsampled for this dataset at 5%, and thus receives a 20x weighting in the scoring metric.</span>\n",
    "\n",
    "### Problem Description\n",
    "\n",
    "A classification data set with skewed class proportions is called **imbalanced**. Classes that make up a large proportion of the data set are called **majority classes**. Those that make up a smaller proportion are **minority classes**. Machine learning techniques often fail or give misleadingly optimistic performance on classification datasets with an imbalanced class distribution.\n",
    "\n",
    "The reason is that many machine learning algorithms are designed to operate on classification data with an equal number of observations for each class. When this is not the case, algorithms can learn that very few examples are not important and can be ignored in order to achieve good performance. As such, many machine learning algorithms, like decision trees, k-nearest neighbors, and neural networks, will therefore learn that the minority class is not as important as the majority class and put more attention and perform better on the majority class. **This is a problem because the minority class is exactly the class that we care most about in imbalanced classification problems.** The reason for this is because the majority class often reflects a normal case, whereas the minority class represents a positive case for a diagnostic, fault, fraud, or other types of exceptional circumstance.\n",
    "\n",
    "### Solutions\n",
    "\n",
    "#### 1. Balance the Class Distribution With Data Sampling\n",
    "The most popular solution to an imbalanced classification problem is to change the composition of the training dataset.\n",
    "\n",
    "**Techniques designed to change the class distribution in the training dataset are generally referred to as sampling methods** or resampling methods as we are sampling an existing data sample. \n",
    "\n",
    "The reason that sampling methods are so common is because they are simple to understand and implement, and because once applied to transform the training dataset, a suite of standard machine learning algorithms can then be used directly.\n",
    "\n",
    "This means that any from tens or hundreds of machine learning algorithms developed for balanced (or mostly balanced) classification can then be fit on the training dataset without any modification adapting them for the imbalance in observations.\n",
    "\n",
    "1. **Undersampling Techniques:** Undersampling methods delete or select a subset of examples from the majority class. Undersampling can be defined as removing some observations of the majority class. Undersampling can be a good choice when you have a ton of data -think millions of rows. But a drawback is that we are removing information that may be valuable. This could lead to underfitting and poor generalization to the test set.\n",
    "\n",
    "    Of 458913 customer_IDs in the training data, 340085 (~ **74%**) have a label of 0 (good customer, no default) and 118828 (~ **26%**) have a label of 1 (bad customer, default). In reality, however, American Express has subsampled the negative class for this dataset at 5%. This means that :\n",
    "    \n",
    "    `Total number of negative samples x 5/100 = 340085 => Total number of negative samples = (340085 x 100) / 5 = ~6.8 million non-defaulting customers` \n",
    "    \n",
    "    Out of 6920528 total training samples the ~ 6.8 million are non-defaulting customers (**98%**) and only **2%** are the bad customers. \n",
    "    \n",
    "    Downsampling means you sample from the majority class (the 98.5%) to reduce the imbalance between majority and minority class. If you keep the ratio constant you simply reduce your number of trainings examples. This doesn't make sense. However, you don't have to sample down to a ratio of 50:50. If you have a ratio of 98:2, you can sample to 80:2 instead of 2:2.\n",
    "    \n",
    "    The main goal of downsampling (and upsampling) is to increase the discriminative power between the two classes. Ideally, you would have a classifier that outputs a decision surface that is not simply binary (e.g. logistic regression (where you don't have to select a cut-off point of 0.5)) but gives you a continuous decision value. You can then order the data and set a decision threshold that gives you the best outcome.\n",
    "    \n",
    "    Since downsampling (or upsampling) changes your training distribution from your true distribution, you only want to downsample (or upsample) so much that your classifier can start discriminating between the two classes. **You then fine-tune the results by selecting an appropriate decision threshold.**\n",
    "    \n",
    "    **Downsampling and Upweighting**\n",
    "    \n",
    "    An effective way to handle imbalanced data is to downsample and upweight the majority class. Let's start by defining those two new terms:\n",
    "    \n",
    "    1. **Downsampling (in this context)** means training on a disproportionately low subset of the majority class examples.\n",
    "\n",
    "    1. **Upweighting** means adding an example weight to the downsampled class equal to the factor by which you downsampled.\n",
    "    \n",
    "    Step 1: Downsample the majority class. Consider again our example of the fraud data set, with 1 positive to 200 negatives. Downsampling by a factor of 20 improves the balance to 1 positive to 10 negatives (10%). Although the resulting training set is still moderately imbalanced, the proportion of positives to negatives is much better than the original extremely imbalanced proportion (0.5%).\n",
    "    \n",
    "    Step 2: Upweight the downsampled class: The last step is to add example weights to the downsampled class. **Since we downsampled by a factor of 20, the example weight should be 20.** You may be used to hearing the term weight when it refers to model parameters, like connections in a neural network. Here we're talking about example weights, which means counting an individual example more importantly during training. An example weight of 10 means the model treats the example as 10 times as important (when computing loss) as it would an example of weight 1. **The weight should be equal to the factor you used to downsample:**\n",
    "    \n",
    "    <img width=\"782\" alt=\"image\" src=\"https://user-images.githubusercontent.com/28102493/220610379-e5485e1e-bc29-4166-a0de-62a6fc70bde6.png\">\n",
    "    \n",
    "    **Why Downsample and Upweight?**\n",
    "\n",
    "    It may seem odd to add example weights after downsampling. We were trying to make our model improve on the minority class -- why would we upweight the majority? These are the resulting changes:\n",
    "\n",
    "    1. **Faster convergence:** During training, we see the minority class more often, which will help the model converge faster.\n",
    "\n",
    "    1. **Disk space:** By consolidating the majority class into fewer examples with larger weights, we spend less disk space storing them. This savings allows more disk space for the minority class, so we can collect a greater number and a wider range of examples from that class.\n",
    "\n",
    "    1. **Calibration:** Upweighting ensures our model is still calibrated; the outputs can still be interpreted as probabilities.\n",
    "\n",
    "1. **Oversampling Techniques**\n",
    "1. **Combination of both of them**\n",
    "\n",
    "\n",
    "### 2. Weighted Loss Functions\n",
    "\n",
    "In undersampling, you randomly remove samples from the majority class so that the ratio of the minority class to the majority class is more balanced. However, this can result in loss of valuable information from the majority class, which may lead to a model that does not generalize well.\n",
    "\n",
    "To avoid this issue, some practitioners use \"weighted loss functions\", **which assign higher weight to the underrepresented class in the loss function to give it more importance during training.** However, if the loss function is not properly weighted, the model may be biased towards the majority class.\n",
    "\n",
    "\n",
    "### 3. Choose an appropriate Evaluation Metric\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd9fbc8",
   "metadata": {
    "papermill": {
     "duration": 0.012115,
     "end_time": "2023-02-27T12:45:38.254682",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.242567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding:20px;color:white;margin:0;font-size:24px;text-align:left;display:fill;border-radius:5px;background-color:#3A578A;overflow:hidden\">Evaluation Metric Explained</div>\n",
    "\n",
    "\n",
    "## <span style=\"color: #3A578A;\">Recall: True Positive Rate</span>\n",
    "\n",
    "Recall attempts to answer the following question:\n",
    "\n",
    "What proportion of actual positives was identified correctly? => **How many actual positives the model predicted correctly.**\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/28102493/220618679-2c62cf78-b5ca-4e1f-ab30-edbeb9284f12.png)\n",
    "\n",
    "## <span style=\"color: #3A578A;\">False Positive Rate</span>\n",
    "\n",
    "What is False Positive Rate?\n",
    "\n",
    "In data science, the false positive rate measures the percentage of false positives against all negative predictions (the sum of false positives and true negatives) in a binary classification problem. The false positive rate is based on **how many actual negatives the model predicted incorrectly.** This metric is complementary to the true positive rate, or recall, which shows how many actual positives the model predicted correctly.\n",
    "The false positive rate is calculated as FP/FP+TN, where FP is the number of false positives and TN is the number of true negatives (FP+TN being the total number of negatives). It's the probability that a false alarm will be raised\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/28102493/220620304-6ea4d3e6-f4ff-46ee-8ed6-636be77a0ff2.png)\n",
    "\n",
    "## <span style=\"color: #3A578A;\">ROC curve</span>\n",
    "\n",
    "An ROC curve (receiver operating characteristic curve) **is a graph showing the performance of a classification model at all classification thresholds.** This curve plots two parameters:\n",
    "\n",
    "- True Positive Rate\n",
    "- False Positive Rate\n",
    "\n",
    "In a binary classification problem, the output of a classifier can be represented as a probability score between 0 and 1, where values close to 0 indicate that the sample belongs to the negative class and values close to 1 indicate that the sample belongs to the positive class. **The decision classification threshold is the probability value above which a sample is classified as belonging to the positive class and below which it is classified as belonging to the negative class.**\n",
    "\n",
    "ROC (Receiver Operating Characteristic) is a plot that visualizes the performance of a binary classifier at different decision classification thresholds. The plot shows the true positive rate (TPR) on the y-axis, and the false positive rate (FPR) on the x-axis, at different threshold values. The **TPR** is the proportion of true positive predictions (i.e., **correctly classified positive samples) among all positive samples**, while the FPR is the proportion of false positive predictions (i.e., **incorrectly classified negative samples) among all negative samples.**\n",
    "\n",
    "**As the decision classification threshold is varied from 0 to 1, the TPR and FPR change, and this change is represented as a curve in the ROC plot.** The curve starts at the point (0,0) (corresponding to a threshold of 1, which classifies all samples as negative) and moves towards the point (1,1) (corresponding to a threshold of 0, which classifies all samples as positive). **The area under this curve (AUC) is a measure of the classifier's overall performance, where an AUC of 1 indicates perfect performance and an AUC of 0.5 indicates random performance.**\n",
    "\n",
    "Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives. The following figure shows a typical ROC curve.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/28102493/220627394-9fe48f3b-2740-4bfb-a9fc-86c47fb665a3.png)\n",
    "\n",
    "\n",
    "TP vs. FP rate at different classification thresholds.\n",
    "\n",
    "To compute the points in an ROC curve, we could evaluate a logistic regression model many times with different classification thresholds, but this would be inefficient. Fortunately, there's an efficient, sorting-based algorithm that can provide this information for us, called AUC.\n",
    "\n",
    "<img width=\"810\" alt=\"image\" src=\"https://user-images.githubusercontent.com/28102493/221170676-43f81237-46e7-4582-93d3-6865eefc175e.png\">\n",
    "\n",
    "\n",
    "AUC stands for \"Area under the ROC Curve.\" That is, AUC measures the entire two-dimensional area underneath the entire ROC curve (think integral calculus) from (0,0) to (1,1).\n",
    "AUC provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example. \n",
    "\n",
    "AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0.\n",
    "\n",
    "AUC is desirable for the following two reasons:\n",
    "\n",
    "1. AUC is scale-invariant. It measures how well predictions are ranked, rather than their absolute values.\n",
    "\n",
    "1. AUC is classification-threshold-invariant. It measures the quality of the model's predictions irrespective of what classification threshold is chosen.\n",
    "\n",
    "### Purpose of ROC Curve: Purpose 1 — Determining optimal threshold\n",
    "However, both these reasons come with caveats, which may limit the usefulness of AUC in certain use cases:\n",
    "\n",
    "1. **Scale invariance** is not always desirable. For example, sometimes we really do need well calibrated probability outputs, and AUC won’t tell us about that.\n",
    "\n",
    "1. **Classification-threshold invariance is not always desirable.** In cases where there are wide disparities in the cost of false negatives vs. false positives, it may be critical to minimize one type of classification error. For example, when doing email spam detection, you likely want to prioritize minimizing false positives (even if that results in a significant increase of false negatives). AUC isn't a useful metric for this type of optimization. **The performance of our system would vary as we change this threshold. It can be adjusted to tune the behavior of the model to reduce more of one or another type of error (FP/FN).**\n",
    "\n",
    "We have a classification model that predicts the probability that an observation belongs to Class YES. This probability can range from 0 to 1. The default threshold of 0.5 that is used to determine the class of this observation is not always the best threshold. The ROC curve helps us find the threshold where the TPR is high and FPR is low i.e. misclassifications are low. Therefore, ROC curves should be used to determine the optimal probability threshold for a classification model.\n",
    "\n",
    "\n",
    "**Example:**\n",
    "\n",
    "<img width=\"645\" alt=\"image\" src=\"https://user-images.githubusercontent.com/28102493/220629275-179436bd-fb5c-4a34-a2a4-383a674c85f7.png\">\n",
    "\n",
    "\n",
    "1. In the above curve if you wanted a model with a very low false positive rate, you might pick 0.8 as your threshold of choice. If you favour a low FPR, but you don’t want an abysmal TPR, you might go for 0.5, the point where the curve starts turning hard to the right.\n",
    "\n",
    "2. If you prefer a low false negative rate/high TPR, you might decide that somewhere between 0.2 and 0.1 is the region where you start getting severely diminishing returns for improving the TPR any further.\n",
    "\n",
    "3. Notice the graph at threshold 0.5 and 0.4. The TPR at both the thresholds is ~0.6, but FPR is higher at threshold 0.4. It’s clear that if we are happy with TPR = 0.6 we should choose threshold = 0.5.\n",
    "\n",
    "## <span style=\"color: #3A578A;\">Lorenz Curve & Gini Coefficient</span>\n",
    "\n",
    "### Definition\n",
    "A Lorenz curve, developed by American economist Max Lorenz in 1905, is a graphical representation of income inequality or wealth inequality. **The graph plots percentiles of the population on the horizontal axis according to income or wealth and plots cumulative income or wealth on the vertical axis.**\n",
    "\n",
    "<img width=\"690\" alt=\"image\" src=\"https://user-images.githubusercontent.com/28102493/220911221-f3384f45-e884-45fe-836c-1a20059b549e.png\">\n",
    "\n",
    "In practice, a Lorenz curve is usually a mathematical function estimated from an incomplete set of observations of income or wealth. **The Lorenz curve is often accompanied by a straight diagonal line with a slope of 1, which represents perfect equality in income or wealth distribution; the Lorenz curve lies beneath it, showing the observed or estimated distribution.**\n",
    "\n",
    "**While the Lorenz curve is most often used to represent economic inequality, it can also demonstrate unequal distribution in any system. The farther the curve is from the baseline, represented by the straight diagonal line, the higher the level of inequality.**\n",
    "\n",
    "In economics, the Lorenz curve denotes inequality in the distribution of either wealth or income. These are not synonymous since it is possible to have either high earnings but zero or negative net worth, or low earnings but a large net worth. \n",
    "\n",
    "- The x-axis is often denoted as the percentile. \n",
    "\n",
    "- The y-axis is often denoted as the cumulative percentage of occurrences.\n",
    "\n",
    "- The line of equality is demonstrated by a 45-degree, upward-sloping line. In the graph above, it is denoted as the dashed line.\n",
    "\n",
    "- The Lorenz curve is demonstrated often by an upward-sloping but often exponentially rising curve. In the graph above, it is denoted as a solid line.\n",
    "\n",
    "- The Gini coefficient (discussed below) is the gap between the line of equality and the Lorenz curve.\n",
    "\n",
    "### Example\n",
    "\n",
    "The curve above shows a continuous Lorenz curve that has been fitted to data that describes income distribution in Brazil as of 2020. The data set is also compared to a straight diagonal line representing perfect equality.\n",
    "\n",
    "At the 55th income percentile, the value of the Lorenz curve is 22.39%. This means that the Lorenz curve estimates that the bottom 55% of the population takes in 22.39% of the nation’s total income. If Brazil were a perfectly equal society, the bottom 55% would earn 55% of the total.\n",
    "\n",
    "Elsewhere, we can see that the 99th percentile corresponds to 89.32% in cumulative income. This means that the top 1% takes in 11.68% of Brazil’s income.\n",
    "\n",
    "\n",
    "\n",
    "### KEY TAKEAWAYS\n",
    "\n",
    "- A Lorenz curve is a graphical representation of the distribution of income or wealth within a population.\n",
    "\n",
    "- Lorenz curves graph percentiles of the population against cumulative income or wealth of people at or below that percentile. \n",
    "\n",
    "- Lorenz curves, along with their derivative statistics, are widely used to measure inequality across a population. \n",
    "\n",
    "- The Lorenz curve is a central piece in calculating **the Gini coefficient, a mathematical representation of inequality levels.**\n",
    "\n",
    "- Because Lorenz curves are mathematical estimates based on fitting a continuous curve to incomplete and discontinuous data, they may be imperfect measures of true inequality.\n",
    "\n",
    "### Gini Coefficient\n",
    "\n",
    "**The Gini coefficient is used to express the extent of inequality in a single figure.** The Gini coefficient measures the inequality in a distribution, and **its range depends on the context in which it is used.** It most often ranges from 0 (or 0%) to 1 (or 100%). Complete equality, in which every individual has the exact same income or wealth, corresponds to a coefficient of 0. Plotted as a Lorenz curve, complete equality would be a straight diagonal line with a slope of 1 (the area between this curve and itself is 0, so the Gini coefficient is 0).\n",
    "\n",
    "A coefficient of 1 means that one person earns all of the income or holds all of the wealth. A Gini coefficient of 0.5 would represent a situation where half the population has half the income or wealth, and the other half has the other half.\n",
    "\n",
    "In theory, the Gini coefficient can exceed 100% in extreme situations. For example, when handling negative wealth or income, the figure can theoretically be higher than 1; in that case, the Lorenz curve would dip below the horizontal axis.\n",
    "\n",
    "**The Gini coefficient is equal to the area below the line of perfect equality minus the area below the Lorenz curve, divided by the area below the line of perfect equality.** In the graph above, the Gini coefficient is the area below the dashed line but above the solid line. The Gini coefficient is used to measure the extent of inequality. It can also be used to compare two different nations or countries to see which has more inequality.\n",
    "\n",
    "<img width=\"624\" alt=\"image\" src=\"https://user-images.githubusercontent.com/28102493/220958224-c0080cf7-1518-487a-b7e6-2b2aa1444d3e.png\">\n",
    "\n",
    "\n",
    "### Gini Coefficient in Binary Classification Problems\n",
    "In this section I will explain the Gini coefficient’s usage and relevance for the data science professionals.\n",
    "\n",
    "\n",
    "**The Gini coefficient is a popular metric on Kaggle, especially for imbalanced class values.** But googling \"Gini coefficient\" gives you mostly economic explanations. Here is a descriptive explanation with regard to using it as an evaluation metric in classification.\n",
    "\n",
    "In the context of evaluating a binary classifier, such as a credit default model, the Gini coefficient is typically scaled to the range [0, 1]. A perfect classifier that correctly separates all positive and negative examples would have a Gini coefficient of 1, while a completely random classifier with no predictive power would have a Gini coefficient of 0. A classifier that performs worse than random would have a negative Gini coefficient. The Gini Coefficient is `2 * AUC – 1`, and its purpose is to normalize the AUC so that a random classifier scores 0, and a perfect classifier scores 1. \n",
    "\n",
    "***Why the Gini coefficient metric is preferred especially for imbalanced class classification problems?***\n",
    "\n",
    "**Gini or the Gini coefficient is one of the most popular metrics used by the financial industry for evaluating the performance of credit score models** because it has several desirable properties for assessing binary classification models:\n",
    "\n",
    "1. Firstly, the Gini coefficient **is sensitive to the correct ranking of examples, which is particularly important in credit scoring where the focus is on identifying high-risk customers. This means that the metric is able to effectively capture the relative ordering of the predictions made by the model.** The Gini coefficient metric is preferred for imbalanced classification problems because it is sensitive to the ranking of the predicted probabilities of the positive class. In imbalanced problems, the minority class is of particular interest, but it is also more difficult to predict accurately due to its low prevalence. Therefore, metrics that rely on absolute counts, such as accuracy or precision, can be misleading and may not reflect the true performance of a model. Moreover, the Gini coefficient is particularly useful in evaluating models that are intended for ranking or scoring purposes, such as credit scoring or fraud detection, where the objective is to rank the instances according to their likelihood of belonging to the positive class, rather than to make binary predictions.\n",
    "\n",
    "1. Secondly, the Gini coefficient is relatively **robust to class imbalance**, which is often a problem in credit scoring where the number of bad (i.e., high-risk) customers is typically much smaller than the number of good (i.e., low-risk) customers.\n",
    "\n",
    "1. Lastly, the Gini coefficient is easy to understand and interpret, which makes it a popular choice for both model developers and end-users. It provides a simple and **intuitive way to measure the predictive power of a credit score model, which can be used to compare different models and to make decisions about which model to use in practice.** The Gini coefficient is a metric that indicates the model’s discriminatory power, namely, the effectiveness of the model in differentiating between “bad” borrowers, who will default in the future, and “good” borrowers, who won’t default in the future. This metric is often used to compare the quality of different models and evaluate their prediction power.\n",
    "\n",
    "\n",
    "**In summary, the Gini coefficient is preferred for imbalanced classification problems because it is a ranking-based metric that is sensitive to the performance of a model in distinguishing between the positive and negative classes, regardless of their relative sizes, and is particularly useful for evaluating models that are intended for ranking or scoring purposes.**\n",
    "\n",
    "### Intuitive Explanation of the Gini coefficient calculation for binary classification problems\n",
    "\n",
    "It is calculated based on the distribution of the predicted probabilities for the positive class (the class of interest). \n",
    "\n",
    "The Gini coefficient compares the cumulative distribution of the predicted probabilities of the positive class to the cumulative distribution of a uniform random variable. This comparison provides a measure of how well the model is able to distinguish between the positive and negative classes, regardless of their relative sizes.\n",
    "\n",
    "The calculation involves the following steps:\n",
    "\n",
    "#### Step 1: Sort the predicted probabilities in descending order\n",
    "In Gini coefficient they go through the population from poorest to richest and plot the running total / cumulative share of income, which gives them the Lorenz Curve. The Gini coefficient is then defined as the blue area divided by the total area of the triangle.\n",
    "\n",
    "<img width=\"644\" alt=\"image\" src=\"https://user-images.githubusercontent.com/28102493/221203026-c19eefb3-3707-43ed-bf47-e122d79f0124.png\">\n",
    "\n",
    "Instead of going through the population from poorest to richest, we go through our predictions from highest to lowest.\n",
    "\n",
    "Sort the predicted probabilities in descending order, from highest to lowest. The Lorenz curve is the inverse of the CAP curve; it is constructed using the same mechanism of sampling observations and aggregating the cumulative default rate, but the sampling is done in reverse order (from highest to lowest score). \n",
    "\n",
    "<img width=\"717\" alt=\"image\" src=\"https://user-images.githubusercontent.com/28102493/221240235-4c7083de-a7c3-44c5-a434-ac27aa0ac0ac.png\">\n",
    "\n",
    "When using the Lorenz curve to evaluate an imbalance binary classification problem, we should sort the probabilities by descending order.\n",
    "\n",
    "The Lorenz curve is a graphical representation of the cumulative distribution function (CDF) of a variable. In the context of binary classification, the variable of interest is the predicted probability of belonging to the positive class. Sorting the probabilities in descending order means that we are placing the highest predicted probabilities at the top of the curve, and the lowest predicted probabilities at the bottom.\n",
    "\n",
    "The Lorenz curve is used to assess the degree of imbalance in the binary classification problem by comparing the actual distribution of positive samples to the ideal distribution. The ideal distribution assumes that the positive samples are ranked in descending order of their predicted probabilities. By sorting the probabilities in descending order, we are aligning the actual distribution of positive samples with the ideal distribution.\n",
    "\n",
    "In summary, sorting the probabilities by descending order is recommended when using the Lorenz curve to evaluate an imbalance binary classification problem because it aligns the actual distribution of positive samples with the ideal distribution.\n",
    "\n",
    "The Lorenz curve is typically sorted in ascending order. This is because in economics, the variable of interest is typically a measure of economic inequality, such as income or wealth. In this context, the Lorenz curve is used to show the distribution of income or wealth across a population, and the ideal distribution assumes that everyone has an equal share.\n",
    "\n",
    "When the Lorenz curve is sorted in ascending order, the x-axis represents the cumulative proportion of the population, starting from the poorest individuals and increasing towards the richest. The y-axis represents the cumulative proportion of the total income or wealth held by that proportion of the population.\n",
    "\n",
    "The difference in sorting order between the use of the Lorenz curve in economics and in binary classification problems arises from the different variables of interest. In economics, the Lorenz curve is used to show the distribution of income or wealth, and it is sorted in ascending order to compare the actual distribution to the ideal distribution of equal shares. In binary classification problems, the Lorenz curve is used to assess the degree of imbalance in the predicted probabilities of belonging to the positive class, and it is sorted in descending order to align the actual distribution of positive samples with the ideal distribution.\n",
    "\n",
    "In summary, the sorting order of the Lorenz curve depends on the variable of interest and the specific context in which it is being used. In economics, the Lorenz curve is typically sorted in ascending order to show the distribution of income or wealth, while in binary classification problems, it is sorted in descending order to assess the degree of imbalance in predicted probabilities.\n",
    "\n",
    "\n",
    "**Other explanation:**\n",
    "\n",
    "\n",
    "The Gini coefficient is a measure of the inequality of a distribution, often used in the context of evaluating imbalanced binary classification problems. When calculating the Gini coefficient for a binary classification problem, the true class labels are typically represented as 0 (for the negative or majority class) and 1 (for the positive or minority class).\n",
    "\n",
    "To calculate the Gini coefficient for a given binary classifier, we need to sort the predicted probabilities for the positive class in descending order. This is because the Gini coefficient measures the extent to which the positive class is overrepresented at the top of the sorted list of predictions. The more the positive class is concentrated at the top of the list, the higher the Gini coefficient, indicating better performance.\n",
    "\n",
    "In contrast, the Lorenz curve is used to visualize the degree of inequality in a distribution by plotting the cumulative proportion of the population against the cumulative proportion of the resource being measured. The Lorenz curve is used to illustrate the degree of inequality in a distribution, but it does not measure the performance of a binary classification model.\n",
    "\n",
    "\n",
    "When we sort the predicted probabilities in descending order for a binary classification problem, we are effectively creating a ranking of the instances according to their likelihood of belonging to the positive class. This ranking can be used to construct the Lorenz curve by plotting the cumulative proportion of the positive class instances on the y-axis against the cumulative proportion of the instances on the x-axis.\n",
    "\n",
    "If the predicted probabilities are well-calibrated, meaning that they accurately reflect the true likelihood of the instances belonging to the positive class, then the Lorenz curve will generally lie above the diagonal line. This is because the instances that are more likely to belong to the positive class will be concentrated towards the top of the ranking, and as we move up the ranking, the proportion of positive class instances will increase more quickly than the proportion of instances overall.\n",
    "\n",
    "This results in a curve that is above the diagonal line, indicating that the distribution of the positive class is more concentrated towards the top of the ranking than would be expected under perfect balance. On the other hand, if the predicted probabilities are poorly calibrated, then the Lorenz curve may lie below the diagonal line or be close to it, indicating that the positive class is not well-separated from the negative class and that the binary classifier is not performing well.\n",
    "\n",
    "In summary, when we sort the probabilities in descending order, the Lorenz curve is shaped above the diagonal line if the predicted probabilities are well-calibrated and accurately reflect the true likelihood of the instances belonging to the positive class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e2cefb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.281910Z",
     "iopub.status.busy": "2023-02-27T12:45:38.281467Z",
     "iopub.status.idle": "2023-02-27T12:45:38.295077Z",
     "shell.execute_reply": "2023-02-27T12:45:38.293881Z"
    },
    "papermill": {
     "duration": 0.030383,
     "end_time": "2023-02-27T12:45:38.297804",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.267421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction  target\n",
       "0         0.9       1\n",
       "1         0.3       0\n",
       "2         0.8       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [0.9, 0.3, 0.8, 0.75, 0.65, 0.6, 0.78, 0.7, 0.05, 0.4, 0.4, 0.05, 0.5, 0.1, 0.1]\n",
    "actual = [1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "data = {\"prediction\":predictions, \"target\": actual}  \n",
    "data_df = pd.DataFrame(data)  \n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dee7e6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.325475Z",
     "iopub.status.busy": "2023-02-27T12:45:38.325057Z",
     "iopub.status.idle": "2023-02-27T12:45:38.331674Z",
     "shell.execute_reply": "2023-02-27T12:45:38.330666Z"
    },
    "papermill": {
     "duration": 0.023225,
     "end_time": "2023-02-27T12:45:38.333835",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.310610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "262ef299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.361163Z",
     "iopub.status.busy": "2023-02-27T12:45:38.360703Z",
     "iopub.status.idle": "2023-02-27T12:45:38.376389Z",
     "shell.execute_reply": "2023-02-27T12:45:38.375171Z"
    },
    "papermill": {
     "duration": 0.032229,
     "end_time": "2023-02-27T12:45:38.378789",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.346560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  prediction\n",
       "0        1        0.90\n",
       "2        1        0.80\n",
       "6        0        0.78\n",
       "3        1        0.75\n",
       "7        0        0.70\n",
       "4        0        0.65\n",
       "5        1        0.60\n",
       "12       0        0.50\n",
       "9        0        0.40\n",
       "10       0        0.40\n",
       "1        0        0.30\n",
       "13       0        0.10\n",
       "14       0        0.10\n",
       "8        0        0.05\n",
       "11       0        0.05"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (pd.concat([data_df[\"target\"], data_df[\"prediction\"]], axis='columns').sort_values('prediction', ascending=False))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a2ab001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.408115Z",
     "iopub.status.busy": "2023-02-27T12:45:38.407662Z",
     "iopub.status.idle": "2023-02-27T12:45:38.413895Z",
     "shell.execute_reply": "2023-02-27T12:45:38.413060Z"
    },
    "papermill": {
     "duration": 0.024324,
     "end_time": "2023-02-27T12:45:38.416879",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.392555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "data = zip(actual, predictions)\n",
    "sorted_data = sorted(data, key=lambda d: d[1], reverse=True)\n",
    "sorted_actual = [d[0] for d in sorted_data]\n",
    "print(sorted_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a6474",
   "metadata": {
    "papermill": {
     "duration": 0.012629,
     "end_time": "2023-02-27T12:45:38.443345",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.430716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Step 2: Sum up the actual values - Calculate Lorenz Curve\n",
    "\n",
    "Instead of summing up the income, we sum up the actual values of our predictions by taking into account their weight as well:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c25d80cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.471698Z",
     "iopub.status.busy": "2023-02-27T12:45:38.471304Z",
     "iopub.status.idle": "2023-02-27T12:45:38.485186Z",
     "shell.execute_reply": "2023-02-27T12:45:38.484020Z"
    },
    "papermill": {
     "duration": 0.03095,
     "end_time": "2023-02-27T12:45:38.487695",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.456745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  prediction  weight\n",
       "0        1        0.90       1\n",
       "2        1        0.80       1\n",
       "6        0        0.78      20\n",
       "3        1        0.75       1\n",
       "7        0        0.70      20\n",
       "4        0        0.65      20\n",
       "5        1        0.60       1\n",
       "12       0        0.50      20\n",
       "9        0        0.40      20\n",
       "10       0        0.40      20\n",
       "1        0        0.30      20\n",
       "13       0        0.10      20\n",
       "14       0        0.10      20\n",
       "8        0        0.05      20\n",
       "11       0        0.05      20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We assign the weight to the majority class (0) that we subsample\n",
    "df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f503b7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.516318Z",
     "iopub.status.busy": "2023-02-27T12:45:38.515905Z",
     "iopub.status.idle": "2023-02-27T12:45:38.523892Z",
     "shell.execute_reply": "2023-02-27T12:45:38.522691Z"
    },
    "papermill": {
     "duration": 0.025218,
     "end_time": "2023-02-27T12:45:38.526332",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.501114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum up the targets\n",
    "total_pos = (df['target'] * df['weight']).sum()\n",
    "total_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "644c3402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.555730Z",
     "iopub.status.busy": "2023-02-27T12:45:38.554541Z",
     "iopub.status.idle": "2023-02-27T12:45:38.570145Z",
     "shell.execute_reply": "2023-02-27T12:45:38.568966Z"
    },
    "papermill": {
     "duration": 0.033004,
     "end_time": "2023-02-27T12:45:38.572731",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.539727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>weight</th>\n",
       "      <th>cum_pos_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  prediction  weight  cum_pos_found\n",
       "0        1        0.90       1              1\n",
       "2        1        0.80       1              2\n",
       "6        0        0.78      20              2\n",
       "3        1        0.75       1              3\n",
       "7        0        0.70      20              3\n",
       "4        0        0.65      20              3\n",
       "5        1        0.60       1              4\n",
       "12       0        0.50      20              4\n",
       "9        0        0.40      20              4\n",
       "10       0        0.40      20              4\n",
       "1        0        0.30      20              4\n",
       "13       0        0.10      20              4\n",
       "14       0        0.10      20              4\n",
       "8        0        0.05      20              4\n",
       "11       0        0.05      20              4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of summing up the income, we sum up the actual values of our predictions\n",
    "# This corresponds to the Lorenz Curve in the diagram above. See the following chart\n",
    "df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8853fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.602201Z",
     "iopub.status.busy": "2023-02-27T12:45:38.601775Z",
     "iopub.status.idle": "2023-02-27T12:45:38.609827Z",
     "shell.execute_reply": "2023-02-27T12:45:38.608624Z"
    },
    "papermill": {
     "duration": 0.025783,
     "end_time": "2023-02-27T12:45:38.612326",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.586543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum up the actual values\n",
    "cumulative_actual = np.cumsum(sorted_actual)\n",
    "cumulative_index = np.arange(1, len(cumulative_actual)+1)\n",
    "cumulative_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc992959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.641683Z",
     "iopub.status.busy": "2023-02-27T12:45:38.641304Z",
     "iopub.status.idle": "2023-02-27T12:45:38.648061Z",
     "shell.execute_reply": "2023-02-27T12:45:38.646904Z"
    },
    "papermill": {
     "duration": 0.024532,
     "end_time": "2023-02-27T12:45:38.650579",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.626047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4d441bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.680546Z",
     "iopub.status.busy": "2023-02-27T12:45:38.680133Z",
     "iopub.status.idle": "2023-02-27T12:45:38.922865Z",
     "shell.execute_reply": "2023-02-27T12:45:38.921956Z"
    },
    "papermill": {
     "duration": 0.260781,
     "end_time": "2023-02-27T12:45:38.925404",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.664623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(cumulative_index, cumulative_actual)\n",
    "plt.xlabel('Cumulative Number of Predictions')\n",
    "plt.ylabel('Cumulative Actual Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24385812",
   "metadata": {
    "papermill": {
     "duration": 0.01386,
     "end_time": "2023-02-27T12:45:38.953723",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.939863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This corresponds to the Lorenz Curve in the diagram above. \n",
    "**We normalize both axes so that they go from 0 to 100% like in the economic figure** and display the 45° line to illustrate random guessing:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "222f960a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:38.984682Z",
     "iopub.status.busy": "2023-02-27T12:45:38.983650Z",
     "iopub.status.idle": "2023-02-27T12:45:39.000461Z",
     "shell.execute_reply": "2023-02-27T12:45:38.998927Z"
    },
    "papermill": {
     "duration": 0.035014,
     "end_time": "2023-02-27T12:45:39.002930",
     "exception": false,
     "start_time": "2023-02-27T12:45:38.967916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>weight</th>\n",
       "      <th>cum_pos_found</th>\n",
       "      <th>lorentz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  prediction  weight  cum_pos_found  lorentz\n",
       "0        1        0.90       1              1     0.25\n",
       "2        1        0.80       1              2     0.50\n",
       "6        0        0.78      20              2     0.50\n",
       "3        1        0.75       1              3     0.75\n",
       "7        0        0.70      20              3     0.75\n",
       "4        0        0.65      20              3     0.75\n",
       "5        1        0.60       1              4     1.00\n",
       "12       0        0.50      20              4     1.00\n",
       "9        0        0.40      20              4     1.00\n",
       "10       0        0.40      20              4     1.00\n",
       "1        0        0.30      20              4     1.00\n",
       "13       0        0.10      20              4     1.00\n",
       "14       0        0.10      20              4     1.00\n",
       "8        0        0.05      20              4     1.00\n",
       "11       0        0.05      20              4     1.00"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We normalize both axes so that they go from 0 to 100% like in the economic figure and display the 45° line to illustrate random guessing:\n",
    "df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "865d214f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:39.033875Z",
     "iopub.status.busy": "2023-02-27T12:45:39.033435Z",
     "iopub.status.idle": "2023-02-27T12:45:39.254729Z",
     "shell.execute_reply": "2023-02-27T12:45:39.253467Z"
    },
    "papermill": {
     "duration": 0.239985,
     "end_time": "2023-02-27T12:45:39.257596",
     "exception": false,
     "start_time": "2023-02-27T12:45:39.017611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcnklEQVR4nO3deVhU9eIG8HdkRwV33AhRXEBzw1wzc89ybRHTm0vWFTcEl9LMNc3y5lppt3LJ3DBT0zQTN1xQc4FcwA1RXEDEBXCBOTPn+/ujn9wmQGdwZr4zw/t5Hp7HOXOWlyMyr9+zaYQQAkREREQOopjsAERERETmxHJDREREDoXlhoiIiBwKyw0RERE5FJYbIiIicigsN0RERORQWG6IiIjIoTjLDmBtqqrixo0bKFmyJDQajew4REREZAQhBLKyslC5cmUUK/bksZkiV25u3LgBX19f2TGIiIioEK5evYqqVas+cZ4iV25KliwJ4K+d4+XlJTkNERERGSMzMxO+vr65n+NPUuTKzeNDUV5eXiw3REREdsaYU0p4QjERERE5FJYbIiIicigsN0RERORQWG6IiIjIobDcEBERkUNhuSEiIiKHwnJDREREDoXlhoiIiBwKyw0RERE5FJYbIiIicigsN0RERORQpJabffv2oVu3bqhcuTI0Gg02bdr01GWio6MRHBwMd3d3VK9eHd98843lgxIREZHdkFpuHjx4gAYNGuCrr74yav6kpCS8+uqraN26NWJjY/HRRx8hLCwMP//8s4WTEhERkb2Q+lTwLl26oEuXLkbP/8033+C5557D/PnzAQCBgYE4duwYvvjiC7zxxhsWSklERET2RGq5MdWhQ4fQqVMng2mdO3fGkiVLoCgKXFxc8iyTk5ODnJyc3NeZmZkWz0lEzybx5EE8uJMqOwYRFYJTyQqoG9xaaga7Kjepqanw8fExmObj4wOdTof09HRUqlQpzzKzZs3CtGnTrBWRiJ6RUPUoueFfqIE7sqMQkYn+UGvjs+IfYkOw3Bx2d7WURqMxeC2EyHf6YxMmTEBGRkbu19WrVy2ekYgKL+GPKFRgsSGyO0t0XdBXOxF3ipWRHcW+Rm4qVqyI1FTDoeq0tDQ4OzujbNmy+S7j5uYGNzc3a8QjIjPIOhYpOwIRmeChcMOHyvvYoraUHSWXXZWbFi1aYMuWLQbTduzYgSZNmuR7vg0R2Re9TkFA+i7ZMYjISIlqJYQqEbggqsqOYkDqYan79+8jLi4OcXFxAP661DsuLg7JyckA/jqk1L9//9z5Q0NDceXKFYwePRoJCQlYunQplixZgrFjx8qIT0RmlnBoG8oiQ3YMIjLCdv0L6KH9xOaKDSB55ObYsWNo27Zt7uvRo0cDAAYMGIDly5cjJSUlt+gAgL+/P7Zt24aIiAh8/fXXqFy5MhYuXMjLwIkcxMPYdbIjENFT6IUGs3V98F99VwD5n+8qm0Y8PiO3iMjMzIS3tzcyMjLg5eUlOw4R/T9Fm40Hn9ZAKdyXHYWICpAuvDBSGYlDat0C56lW1hN7x7Ut8P3CMuXz267OuSEixxV/cDMasNgQ2axYNQDDtKOQgvwv4LElLDdEZBO0cetlRyCiAqzQdcQM3b+ghX1cvMNyQ0TS5WQ/QOC9fbZ6+J6oyMoWLvhIGYwN6kuyo5iE5YaIpIvftxGNNI9kxyCiv7miVsBQJRzxoprsKCZjuSEi6dRTPCRFZEt26RshQhmKTJSQHaVQWG6ISKpH9zMRmBnDQ1JENkAVGszVvYmv9T0g7O8JTblYbohIqvh96xCsyZEdg6jIuytKYJQyHPvUBrKjPDOWGyKSqtiZjbIjEBV5p9RqGKpE4JooLzuKWbDcEJE09zPvIOj+ER6SIpIoUvcyJusGIgeusqOYDcsNEUlzdu9aNNEosmMQFUk5whmTdYMQqTf/3YRlY7khImlcEjbJjkBUJF0T5TBMOwonRQ3ZUSyC5YaIpMi8nYagh8d4SIrIyvbpn8coZTjuwnGfr2i/13kRkV07u3c1XDR62TGIipQvdT0xUPnQoYsNwJEbIpLE8/wm2RGIioxM4YkIZSh2qcGyo1gFyw0RWd2dm9cQmB3HQ1JEVpCg+iJUicAVUVF2FKvhYSkisroL0avgpBGyYxA5vA36F9FLO71IFRuAIzdEJEHJi1tkRyByaFrhhE907+BHfUcUxSFSlhsisqpb15NQJ+d0Ufx9S2QVqaI0hmlH4YSoJTuKNCw3RGRVidErUZ6HpIgs4pA+CCOVkUiHt+woUrHcEJFVlb70q+wIRA7pG11X/EcXAj2cZEeRjuWGiKwm5co51NadlR2DyKHcF+4Yq4Riu9pUdhSbwXJDRFZzJXolKskOQeRALqhVEKqEI1FUkR3FprDcEJHVlLuyVXYEIofxq74ZPlCG4CHcZUexOSw3RGQV1y6eQoA+UXYMIrunE8UwS/c2luhfBS87zB/LDRFZxdX9K1FVdggiO3dLeGO4Ngx/iEDZUWwayw0RWUWlq9tkRyCya8fUWhimHYU0lJYdxeax3BCRxV2OP4pqarLsGER2a5muMz7V9YPCj22jcC8RkcWlxqxGNdkhiOzQQ+GG8cr72Ky2lB3FrrDcEJFlCYEq17fLTkFkdy6pFRGqROC88JUdxe6w3BCRRV08eRAB4obsGER2ZYc+GGOUociCp+wodonlhogs6tbhNQiQHYLITuiFBl/oQvCNvisEismOY7dYbojIcoRAtdTfZacgsgu3RUmMVEYiRq0nO4rdY7khIos5d3w3aotbsmMQ2bw4tQaGasORgrKyozgElhsispi7f0TKjkBk81bq2mO6rj+0cJEdxWGw3BCRRQhVj+ppUbJjENmsbOGCj3XvYr2+jewoDoflhogsIuHIDgThjuwYRDYpWS2PUCUC8aKa7CgOieWGiCwi6xgPSRHlZ7e+IcKVYchECdlRHBbLDRGZnV6noObtXbJjENkUVWiwQPc6Fup78TJvC2O5ISKzS4jZinrIlB2DyGbcE8URrgzHXrWh7ChFAssNEZndw9h1siMQ2Ywzqh+GKBG4JirIjlJksNwQkVkp2mzUubtXdgwim/CT7iV8rHsXOXCVHaVIYbkhIrNKOPAL6uOB7BhEUuUIZ0zVDcAafTsAGtlxihyTz2g6ceIETp06lfv6l19+Qc+ePfHRRx9Bq9WaNRwR2Z+cP9fLjkAk1XVRFm9pp2CNvj1YbOQwudwMGTIE58+fBwBcunQJffr0gaenJ3766Sd88MEHZg9IRPYjJ/sBAu/tlx2DSJr9+nromjMTJ0UN2VGKNJPLzfnz59GwYUMAwE8//YSXXnoJq1evxvLly/Hzzz+bOx8R2ZEz0RtQQvNIdgwiKb7S9cAAZTzuwkt2lCLP5HNuhBBQVRUAsHPnTnTt2hUA4Ovri/T0dPOmIyK7Ik7xkBQVPZnCA2OUoYhSm8iOQv/P5HLTpEkTzJgxAx06dEB0dDQWL14MAEhKSoKPj4/ZAxKRfXh4PwOBWYd4igEVKWdVX4Qq4bgsKsmOQn9j8mGp+fPn48SJExgxYgQmTpyIgIAAAMD69evRsmVLswckIvuQEL0Onpoc2TGIrGaTviV6aaex2Nggk0du6tevb3C11GP/+c9/4OTkZJZQRGR/ip3ZKDsCkVUowgmf6P6FFfpO4FClbSrUwy3u3buH77//HhMmTMCdO3899Tc+Ph5paWlmDUdE9iHr3m3UfXBEdgwii0sVpRGinYQV+s5gsbFdJo/cnDx5Eu3bt0epUqVw+fJlvP/++yhTpgw2btyIK1euYMWKFZbISUQ27Fz0WjTR6GTHILKow2ogRmpH4hZKyY5CT2HyyM3o0aMxaNAgXLhwAe7u7rnTu3Tpgn379pk1HBHZB5ezm2RHILKob3WvoZ/2IxYbO2HyyM3Ro0fx3//+N8/0KlWqIDU11SyhiMh+ZNxORdDD4xyhJ4f0QLhhnDIE29TmsqOQCUwuN+7u7sjMzMwz/dy5cyhfvrxZQhGR/Ti3dw2aavSyYxCZ3UW1MoYoEUgUVWRHIROZfFiqR48emD59OhRFAQBoNBokJydj/PjxeOONN8wekIhsm+f5X2RHIDK7rfqm6KH9hMXGTplcbr744gvcunULFSpUwKNHj9CmTRsEBASgZMmSmDlzpiUyEpGNun3zKgKz42THIDIbnSiGGUo/DFdG4QE8ZMehQjL5sJSXlxcOHDiA3bt348SJE1BVFY0bN0aHDh0skY+IbNjFvavQTCNkxyAyi1vCCyOVMBxWg2RHoWdkcrl5rF27dmjXrp05sxCRnSl5cYvsCERmcVytiWHaUbiJMrKjkBmYXG6mT5/+xPcnT55c6DBEZD/Srl1CkHJadgyiZ7ZM1xmf6vpBKfz/98nGmPw3uXGj4S3WFUVBUlISnJ2dUaNGDZYboiLiUvRKVJAdgugZPBKuGK+8h1/UF2VHITMz+YTi2NhYg6/Tp08jJSUF7du3R0REhMkBFi1aBH9/f7i7uyM4OBj79+9/4vyrVq1CgwYN4OnpiUqVKmHQoEG4ffu2ydslomdTOulX2RGICi1J9UEv7XQWGwdVqGdL/ZOXlxemT5+OSZMmmbRcZGQkwsPDMXHiRMTGxqJ169bo0qULkpOT853/wIED6N+/PwYPHowzZ87gp59+wtGjR/Hee++Z49sgIiPdSDqL2rpzsmMQFUqUPhg9tDNwVjwnOwpZiFnKDfDXwzQzMjJMWmbu3LkYPHgw3nvvPQQGBmL+/Pnw9fXF4sWL853/8OHDqFatGsLCwuDv748XX3wRQ4YMwbFjxwrcRk5ODjIzMw2+iOjZXNm/SnYEIpPphQazlRD8W4lAJorLjkMWZPI5NwsXLjR4LYRASkoKfvzxR7zyyitGr0er1eL48eMYP368wfROnTohJiYm32VatmyJiRMnYtu2bejSpQvS0tKwfv16vPbaawVuZ9asWZg2bZrRuYjo6Spc4SEpsi93RAmEKSNxQH1edhSyApPLzbx58wxeFytWDOXLl8eAAQMwYcIEo9eTnp4OvV4PHx8fg+k+Pj4FPqOqZcuWWLVqFUJCQpCdnQ2dTofu3bvjyy+/LHA7EyZMwOjRo3NfZ2ZmwtfX1+icRGTo6vk41NBfkh2DyGh/qtUxVBuOGygnOwpZicnlJikpyawBNBrDp+0JIfJMeyw+Ph5hYWGYPHkyOnfujJSUFIwbNw6hoaFYsmRJvsu4ubnBzc3NrJmJirLrB1aD/z0ge7Fa1w7TdP2RA1fZUciKpF3UX65cOTg5OeUZpUlLS8szmvPYrFmz0KpVK4wbNw4AUL9+fRQvXhytW7fGjBkzUKlSJYvnJirShECla9tkpyB6qhzhgo91g/CT/mXZUUgCo8rN66+/bvQKN2zYYNR8rq6uCA4ORlRUFHr16pU7PSoqCj169Mh3mYcPH8LZ2TCyk5MTgL9GfIjIspLij8JfvSo7BtETXVXLI1QJxxnhLzsKSWJUufH29rbIxkePHo133nkHTZo0QYsWLfDtt98iOTkZoaGhAP46X+b69etYsWIFAKBbt254//33sXjx4tzDUuHh4WjatCkqV65skYxE9D83D60GPy7Ilu3VN0C4Mgz3UFJ2FJLIqHKzbNkyi2w8JCQEt2/fxvTp05GSkoJ69eph27Zt8PPzAwCkpKQY3PNm4MCByMrKwldffYUxY8agVKlSaNeuHT7//HOL5COivxECVa9vl52CqEDzda9joe51qOa7ywnZKY0oYsdzMjMz4e3tjYyMDHh5ecmOQ2Q3LsbtR8CmrrJjEOWRITwRrgzHHrWR7CgEoFpZT+wd19bs6zXl87tQJxSvX78e69atQ3JyMrRarcF7J06cKMwqicjGpR9egwDZIYj+IV71wxAlHFdF/heiUNFk8tjdwoULMWjQIFSoUAGxsbFo2rQpypYti0uXLqFLly6WyEhEsgmBaqk7ZKcgMrBe/xJe105lsaE8TC43ixYtwrfffouvvvoKrq6u+OCDDxAVFYWwsDCTH79ARPbh7LFdqIhbsmMQAQC0wgkfKYMxVhmCbPA+ZpSXyeUmOTkZLVu2BAB4eHggKysLAPDOO+9gzZo15k1HRDYh4+ha2RGIAAA3RBn01k7Ban17APnf8JXI5HJTsWJF3L59GwDg5+eHw4cPA/jrzsVF7NxkoiJB1elQPW2n7BhEOKivi645nyJO8OwvejKTy027du2wZcsWAMDgwYMRERGBjh07IiQkxOBmfETkGM7+8TvK467sGFTELdJ1R39lPO6AV7nS0xl9tdSmTZvQrVs3fPvtt1BVFQAQGhqKMmXK4MCBA+jWrVvuzfeIyHFkHV8nOwIVYZnCA2OVUOxQX5AdheyI0fe5cXZ2Rrly5TBgwAC8++67qF27tqWzWQTvc0NkPL1OQeaM6iiNTNlRqAg6p1ZFqBKBJMHnBtoTW7jPjdGHpZKTkzFy5Ehs3LgRQUFBePHFF7Fs2TI8ePDgmQMTkW2Kj9nCYkNS/KJviZ7a6Sw2VCiFukNxdHQ0li5dig0bNkCj0aB3794YPHgwWrRoYYmMZsWRG3oWCUe2Q3lUdAq9+sf3aPgwRnYMKkIU4YSZun5Yru8MXg1ln2xh5OaZHr9w//59rF27FsuWLcPhw4dRp04dnDlzprCrswqWGyqs2zevotSi5+Gk4VWBRJaQJkphmDYMx0Qd2VHoGdhCuSnU4xceK1GiBNq2bYvLly/j7NmzOH/+/LOsjsimXdy7Cs1YbIgs4ohaByO0I3ELpWVHIQdQqEenPnz4ED/88APatGmDWrVqITIyEqNHj8bly5fNHI/Idnhd3Cw7ApFD+l7XBf20H7HYkNmYNHJz8OBBLF26FD/99BN0Oh1ef/117Ny5E23bmn/4iciWpF27hEDFtg+5EtmbB8INHyhDsFVtLjsKORijy02tWrWQmJiIRo0a4fPPP0ffvn3h7e1tyWxENuNS9I+oIDsEkQNJVCthiBKBi6Kq7CjkgIwuN6+88goGDx6MBg0aWDIPkU0qk/Sr7AhEDuM3/QsYpwzBfXjKjkIOyuhys3DhQkvmILJZN5LOopaOJ8sTPSu90OBzXR98q+8KXuZNlvRMV0sRFQXJ+1aisuwQRHYuXXhhpDISh9S6sqNQEcByQ/QU5ZO3yo5AZNdOqAEYph2FVJSVHYWKCJYboie4ej4ONfSXZMcgsls/6Dpihu4dKPy4ISviTxvRE1w7sBq+skMQ2aFHwhUfKYOxUW0tOwoVQUaVG1NOJg4LCyt0GCKbIgQqX9smOwWR3bms+iBUicBZ8ZzsKFREGVVu5s2bZ9TKNBoNyw05jKT4P+CvXpUdg8iuROkbY4wyFJkoLjsKFWFGlZukpCRL5yCyOTdjVsNfdggiO6EKDebo3sIifXeIwj3Zh8hseM4NUX6EgO+N7bJTENmFu6IEwpQR2K/Wlx2FCEAhy821a9ewefNmJCcnQ6vVGrw3d+5cswQjkuli3H4EiFTZMYhs3knVH8OUcFwT5WVHIcplcrnZtWsXunfvDn9/f5w7dw716tXD5cuXIYRA48aNLZGRyOrSj6xFgOwQRDZuja4tpuoGIAeusqMQGTD5wOiECRMwZswYnD59Gu7u7vj5559x9epVtGnTBm+99ZYlMhJZlVD1qJa6Q3YMIpuVI1zwofI+JujeZ7Ehm2RyuUlISMCAAQMAAM7Oznj06BFKlCiB6dOn4/PPPzd7QCJrO3dsDyriluwYRDbpmiiHN7RTEKlvKzsKUYFMLjfFixdHTk4OAKBy5cpITEzMfS89Pd18yYgkuXd0rewIRDYpWl8fXXNm4rSoLjsK0ROZfM5N8+bNcfDgQQQFBeG1117DmDFjcOrUKWzYsAHNmze3REYiq1F1OgTcipIdg8jmLND1wgLdG1B5mTfZAZPLzdy5c3H//n0AwNSpU3H//n1ERkYiICDA6Jv9EdmqhCO/oy7uyY5BZDMyhSfClWHYrfKCEbIfJpeb6tX/Nxzp6emJRYsWmTUQkUwPTkTKjkBkM+JVP4Qq4UgWPrKjEJmEN/Ej+n86bQ5q3t4jOwaRTfhZ/yImKoORDTfZUYhMZnK5KVasGDQaTYHv6/X6ZwpEJEtCzK94HpmyYxBJpRVOmK7rj5X6DgAK/l1PZMtMLjcbN240eK0oCmJjY/HDDz9g2rRpZgtGZG2P4tbLjkAkVYoog2HaUYgVNWVHIXomJpebHj165Jn25ptvom7duoiMjMTgwYPNEozImrTZj1Dn3l7ZMYikidEHYaQyErfhLTsK0TMz2zV9zZo1w86dO821OiKrSjiwCV54KDsGkRSLdd3wjjKBxYYchllOKH706BG+/PJLVK1a1RyrI7I65SQPSVHRkyU8MFYZgt/VprKjEJmVyeWmdOnSBicUCyGQlZUFT09PrFy50qzhiKwh++F9BGYc4LmTVKScV6sgVInAJVFZdhQiszO53MybN8+g3BQrVgzly5dHs2bNULp0abOGI7KG+H3r0ViTLTsGkdVs0TfHh8q/8RDusqMQWYTJ5aZdu3bw9fXN93Lw5ORkPPfcc2YJRmQ1pzfITkBkFTpRDJ/q+mGp/hVwqJIcmcknFPv7++PWrbxPTL59+zb8/f3NEorIWh5k3kVg1iHZMYgsLk2Uwtvaj7FU3wUsNuToTC43Qoh8p9+/fx/u7hziJPuSEL0OHhqt7BhEFvWHWhuv5czEUVFHdhQiqzD6sNTo0aMBABqNBpMnT4anp2fue3q9HkeOHEHDhg3NHpDIkpwSNsmOQGRRS3RdMEv3NnR82g4VIUb/tMfGxgL4a+Tm1KlTcHV1zX3P1dUVDRo0wNixY82fkMhCMu+lo+6DIxyhJ4f0ULjhQ+V9bFFbyo5CZHVGl5s9e/56oOCgQYOwYMECeHl5WSwUkTWc3bMGTTV8Fho5nkS1EkKVCFwQvPcYFU0mj1POnz8fOp0uz/Q7d+7A2dmZpYfshvu5TbIjEJnddv0LGKsMwX14Pn1mIgdl8gnFffr0wdq1a/NMX7duHfr06WOWUESWdu9WCoIenZAdg8hs9EKDWcrbCFXCWWyoyDO53Bw5cgRt27bNM/3ll1/GkSNHzBKKyNLO7V0NZ40qOwaRWaQLL/xL+Qj/1XcDTyIjKsRhqZycnHwPSymKgkePHpklFJGllbjwi+wIRGYRqwZgmHYUUlBWdhQim2HyyM0LL7yAb7/9Ns/0b775BsHBwWYJRWRJ6SlXEJhzUnYMome2QtcRIdpJLDZE/2DyyM3MmTPRoUMH/Pnnn2jfvj0AYNeuXTh69Ch27Nhh9oBE5pYYvQrlNPnfjJLIHmQLF3ykDMYG9SXZUYhskskjN61atcKhQ4fg6+uLdevWYcuWLQgICMDJkyfRunVrS2QkMiuvxC2yIxAV2hW1Al7XTmOxIXqCQt2ysmHDhli1apXBNL1ej02bNqFnz57myEVkETevXUSgEi87BlGh7NI3QoQyFJkoITsKkU175vtxnz17FkuXLsUPP/yAu3fvQqvlc3rIdiXtXQkf2SGITKQKDebp3sBX+p4Qpg+4ExU5hfpX8uDBAyxduhStWrVC3bp1ceLECcycORM3btwwdz4isyp7+VfZEYhMck8UxyDlA3ypf53FhshIJo3cHDp0CN9//z3WrVuHmjVrol+/fjhy5AgWLlyIoKAgS2UkMosbl+JRU3dBdgwio51Sq2GoEo5rooLsKER2xehyExQUhIcPH6Jv3744cuRIbpkZP368xcIRmVPyvpWoLDsEkZEidS9jsm4gcuD69JmJyIDRY5wXL17ESy+9hLZt2yIwMNBsARYtWgR/f3+4u7sjODgY+/fvf+L8OTk5mDhxIvz8/ODm5oYaNWpg6dKlZstDjqvC1a2yIxA9VY5wxofK+/hQ928WG6JCMnrkJikpCcuXL8fQoUPx6NEjvP322+jXrx80msLf6jsyMhLh4eFYtGgRWrVqhf/+97/o0qUL4uPj8dxzz+W7TO/evXHz5k0sWbIEAQEBSEtLy/eOyUR/d+VsLKrrL8uOQfRE10Q5DNOOwklRQ3YUIrumEUKYfDez3bt3Y+nSpdiwYQOys7MxduxYvPfee6hVq5ZJ62nWrBkaN26MxYsX504LDAxEz549MWvWrDzzb9++HX369MGlS5dQpkwZU2MDADIzM+Ht7Y2MjAw+wbwIObxkLJpf/U52DKIC7dM/j1HKcNwFfy+RfatW1hN7x+V9BuWzMuXzu1Cn3rdr1w4rV65ESkoKvvrqK+zevRt16tRB/fr1jV6HVqvF8ePH0alTJ4PpnTp1QkxMTL7LbN68GU2aNMHs2bNRpUoV1KpVC2PHjn3iM61ycnKQmZlp8EVFjBCodP032SmICvSlricGKh+y2BCZyTNdV+jt7Y1hw4bh2LFjOHHiBF5++WWjl01PT4der4ePj+FdR3x8fJCamprvMpcuXcKBAwdw+vRpbNy4EfPnz8f69esxfPjwArcza9YseHt75375+voanZEcw6UzR+CnXpMdgyiPTOGJwdoxmKPrDZWXeROZjdn+NTVs2BALFy40ebl/nrMjhCjwPB5VVaHRaLBq1So0bdoUr776KubOnYvly5cXOHozYcIEZGRk5H5dvXrV5Ixk327GrJYdgSiPBNUX3bQzsEvlA4eJzO2Z71BcWOXKlYOTk1OeUZq0tLQ8ozmPVapUCVWqVIG3t3futMDAQAghcO3aNdSsWTPPMm5ubnBzczNveLIfQsAvZbvsFEQGNuhfxEfKYGSDv5uILEHaOKirqyuCg4MRFRVlMD0qKgotW7bMd5lWrVrhxo0buH//fu608+fPo1ixYqhatapF85J9Oh+7D5XFTdkxiAAAWuGEScpAjFaGstgQWZDUg7yjR4/G999/j6VLlyIhIQERERFITk5GaGgogL8OKfXv3z93/r59+6Js2bIYNGgQ4uPjsW/fPowbNw7vvvsuPDw8ZH0bZMPuHFkjOwIRACBVlEYf7ST8qO8EoPC30CCipzOq3JQpUwbp6ekAgHfffRdZWVlm2XhISAjmz5+P6dOno2HDhti3bx+2bdsGPz8/AEBKSgqSk5Nz5y9RogSioqJw7949NGnSBP369UO3bt0Kda4POT6h6uF/c4fsGEQ4rAaia86nOCFMu10GERWOUfe5KVGiBE6ePInq1avnnidTvnx5a+QzO97npug4e+R31Pmtt+wYVMT9V/caZuv6QA8n2VGIrMIW7nNj1AnFLVq0QM+ePREcHAwhBMLCwgo8DMRHIZCtyDi2TnYEKsLuC3eMU4bgN7WZ7ChERY5R5WblypWYN28eEhMTodFokJGRgezsbEtnIyo0VadDwK2dsmNQEXVBrYJQJRyJoorsKERFklHlxsfHB5999hkAwN/fHz/++CPKli1r0WBEzyL+8DbUwz3ZMagI+lXfDB8q/8YD8CIHIllMvs9NUlKSJXIQmdWDEz/JjkBFjE4Uwyzd21iifxW8GopIrkJdCh4dHY1u3bohICAANWvWRPfu3bF//35zZyMqFJ02B7Xv7JYdg4qQW8IbfbUTsUT/GlhsiOQzudysXLkSHTp0gKenJ8LCwjBixAh4eHigffv2WL2at7kn+eIPbkEp3H/6jERmcEythddyPsUfIlB2FCL6fyYflpo5cyZmz56NiIiI3GmjRo3C3Llz8cknn6Bv375mDUhkqpw/eUiKrGOZrjM+1fWDIu9JNkSUD5NHbi5duoRu3brlmd69e3eej0PSabMfoc69aNkxyME9FG4I047ANN0AFhsiG2RyufH19cWuXbvyTN+1axd8fX3NEoqosOL3b0BJ5P+EeCJzuKRWRE/tdGxW838GHhHJZ/J/OcaMGYOwsDDExcWhZcuW0Gg0OHDgAJYvX44FCxZYIiOR0XQnf5YdgRzYDn0wxihDkQVP2VGI6AlMLjdDhw5FxYoVMWfOHKxb99cdYAMDAxEZGYkePXqYPSCRsbIfZiEo8wAvViGz0wsNvtCF4Bt9Vwi5zxsmIiMU6mBxr1690KtXL3NnIXom8dHr0ViTIzsGOZjboiRGKiMRo9aTHYWIjMQz4chxnN4gOwE5mDi1BoZqw5EC3pGdyJ6w3JBDeJB5F0H3D/GQFJnNKl17TNP1hxYusqMQkYlYbsghJOyNRBONIjsGOYBs4YKPde9ivb6N7ChEVEgsN+QQXBI2yo5ADiBZLY+hSgTOiGqyoxDRMyj0af9arRbnzp2DTqczZx4ik2XcvYXAh0dlxyA7t0ffAN20M1lsiByAyeXm4cOHGDx4MDw9PVG3bl0kJycDAMLCwvDZZ5+ZPSDR05zfsxquGr3sGGSnVKHBPOUNvKuMQwZKyI5DRGZgcrmZMGEC/vzzT+zduxfu7u650zt06IDIyEizhiMyhtv5X2RHIDt1TxTHu8o4LNC/wfvXEDkQk8+52bRpEyIjI9G8eXNoNP+7NCUoKAiJiYlmDUf0NHdv3UDQo1heJUUmO61WQ6gSjmuiguwoRGRmJv9X5datW6hQIe8vgwcPHhiUHSJrOL9nFZw1quwYZGd+0r2EN7RTWWyIHJTJ5eaFF17A1q1bc18/LjTfffcdWrRoYb5kREYoeZGHpMh4OcIZE5TBGKcbghy4yo5DRBZi8mGpWbNm4ZVXXkF8fDx0Oh0WLFiAM2fO4NChQ4iOjrZERqJ8pd+4jDo5p3lIioxyXZTFUG04TooasqMQkYWZPHLTsmVLxMTE4OHDh6hRowZ27NgBHx8fHDp0CMHBwZbISJSvi9GrUEwjZMcgO7BfXw9dc2ay2BAVESaN3CiKgn//+9+YNGkSfvjhB0tlIjJKqUtbZEcgO/CVrgfm6t6CyquhiIoMk/61u7i4YONG3gmW5EtNPo86SoLsGGTDMoUH3teOxhe6EBYboiLG5H/xvXr1wqZNmywQhch4l6NXyo5ANuys6ovu2hmIUpvIjkJEEph8QnFAQAA++eQTxMTEIDg4GMWLFzd4PywszGzhyMYJgVP7N0Ko1j/vxSeJV0lR/jbpW2KC8h4ewf3pMxORQ9IIIUz6ZPL39y94ZRoNLl269MyhLCkzMxPe3t7IyMiAl5eX7Dh27WLcfgRs6io7BhEAQBFOmKH7F37QdwIvoSOSp1pZT+wd19bs6zXl89vkkZukpKRCByPHkn54DQJkhyACcFOUwjDtKBwXtWVHISIbYHK5IQIACIFqqTtkpyDCEbUORmjDcAulZEchIhtRqHJz7do1bN68GcnJydBqtQbvzZ071yzByLadPbYLdXBLdgwq4r7VvYbZuhDo+P80Ivobk38j7Nq1C927d4e/vz/OnTuHevXq4fLlyxBCoHHjxpbISDYo4+ha2RGoCHsg3DBOGYJtanPZUYjIBpl8KfiECRMwZswYnD59Gu7u7vj5559x9epVtGnTBm+99ZYlMpKNUXU6VE/bKTsGFVEX1crorp3BYkNEBTK53CQkJGDAgAEAAGdnZzx69AglSpTA9OnT8fnnn5s9INmehD92oDzuyo5BRdBWfVP00H6CRFFFdhQismEml5vixYsjJycHAFC5cmUkJibmvpeenm6+ZGSz7h+PlB2BihidKIYZSj8MV0bhATxkxyEiG2fyOTfNmzfHwYMHERQUhNdeew1jxozBqVOnsGHDBjRvzmFiR6fXKah1e7fsGFSE3BJeGKmE4bAaJDsKEdkJk8vN3Llzcf/+fQDA1KlTcf/+fURGRiIgIADz5s0ze0CyLfExW/A8MmXHoCLiuFoTw7SjcBNlZEchIjticrmpXr167p89PT2xaNEiswYi2/boxE+yI1ARsUzXGZ/q+kHhZd5EZKJC/9bQarVIS0uDqqoG05977rlnDkW2SdFmo869aNkxyME9Eq6YoLyHTeqLsqMQkZ0yudycP38egwcPRkxMjMF0IQQ0Gg30er3ZwpFtObN/ExrigewY5MAuqz4IVSJwVvA/SURUeCaXm0GDBsHZ2Rm//vorKlWqBI2GD6grKnR/rpcdgRxYlL4xxihDkYnisqMQkZ0zudzExcXh+PHjqFOnjiXykI3KfngfgRn7+bBlMjtVaPCF7i0s1neHMP3uFEREeZhcboKCgng/myIoYd96NNJky45BDuaOKIFRygjsV+vLjkJEDsSo/yZlZmbmfn3++ef44IMPsHfvXty+fdvgvcxMXiLsqMTpDbIjkIP5U62ObjkzWWyIyOyMGrkpVaqUwbk1Qgi0b9/eYB6eUOy4Ht6/h8CsQzwkRWazWtcO03T9kQNX2VGIyAEZVW727Nlj6RxkwxL2/oRgjVZ2DHIAOcIFH+sG4Sf9y7KjEJEDM6rctGnTxtI5yIYVi+chKXp2V9XyCFXCcUb4y45CRA7O6EsT7ty5g2vXrhlMO3PmDAYNGoTevXtj9erVZg9H8mXeS0fdB3/IjkF2bq++AbppZ7DYEJFVGF1uhg8fjrlz5+a+TktLQ+vWrXH06FHk5ORg4MCB+PHHHy0SkuQ5t3ctXDU62THIjs3XvY53lXG4h5KyoxBREWF0uTl8+DC6d++e+3rFihUoU6YM4uLi8Msvv+DTTz/F119/bZGQJI/b2U2yI5CdyhCeGKQdh/m6N6Hy/jVEZEVG/8ZJTU2Fv///hpR3796NXr16wdn5r9N2unfvjgsXLpg/IUlz71YKAh+dkB2D7FC86oeu2pnYozaSHYWIiiCjy42Xlxfu3buX+/qPP/5A8+bNc19rNBrk5OSYNRzJdT56NVw0vLSfTLNe/xJe107FVeEjOwoRFVFGl5umTZti4cKFUFUV69evR1ZWFtq1a5f7/vnz5+Hr62uRkCSH54XNsiOQHdEKJ3ykDMZYZQiy4SY7DhEVYUY/fuGTTz5Bhw4dsHLlSuh0Onz00UcoXbp07vtr167lJeMOJD01GYHZf/LGfWSUG6IMhmnDEScCZEchIjK+3DRs2BAJCQmIiYlBxYoV0axZM4P3+/Tpg6CgILMHJDkS965CM42QHYPswEF9XYxURuIOvGRHISICYOKDM8uXL48ePXrk+95rr71mlkBkG7wSt8iOQHZgka475ujegh5OsqMQEeUy+ang5PhuXruIQOWM7Bhkw7KEB8YqofhdfUF2FCKiPFhuKI+k6FXgdS5UkHNqVYQqEUgSlWRHISLKl/Q7ay1atAj+/v5wd3dHcHAw9u/fb9RyBw8ehLOzMxo2bGjZgEVQmaRfZUcgG7VZ3wK9tNNZbIjIpkktN5GRkQgPD8fEiRMRGxuL1q1bo0uXLkhOTn7ichkZGejfvz/at29vpaRFx42kBNTSnZcdg2yMIpwwVemPMGUEHsJddhwioicqVLlJTEzExx9/jLfffhtpaWkAgO3bt+PMGdPO05g7dy4GDx6M9957D4GBgZg/fz58fX2xePHiJy43ZMgQ9O3bFy1atChMfHqC5H18PhgZShOl8LZ2IpbrXwHvDUBE9sDkchMdHY3nn38eR44cwYYNG3D//n0AwMmTJzFlyhSj16PVanH8+HF06tTJYHqnTp0QExNT4HLLli1DYmKi0dvKyclBZmamwRcVrHzyNtkRyIYcUevgtZyZOCbqyI5CRGQ0k8vN+PHjMWPGDERFRcHV1TV3etu2bXHo0CGj15Oeng69Xg8fH8NTV318fJCamprvMhcuXMD48eOxatWq3GdaPc2sWbPg7e2d+8W7KBcs+XwcauiTZMcgG/G9rgv6aT/CLZR++sxERDbE5HJz6tQp9OrVK8/08uXL4/bt2yYH0GgMh7mFEHmmAYBer0ffvn0xbdo01KpVy+j1T5gwARkZGblfV69eNTljUXH9wCrZEcgGPBBuGK4NwwzdO9DxgkoiskMm/+YqVaoUUlJSDJ4QDgCxsbGoUqWK0espV64cnJyc8ozSpKWl5RnNAYCsrCwcO3YMsbGxGDFiBABAVVUIIeDs7IwdO3YYPOvqMTc3N7i58Tk3TyUEKl/jIamiLlGthCFKBC6KqrKjEBEVmskjN3379sWHH36I1NRUaDQaqKqKgwcPYuzYsejfv7/R63F1dUVwcDCioqIMpkdFRaFly5Z55vfy8sKpU6cQFxeX+xUaGoratWsjLi4uz+MgyDRJ8X/AT70mOwZJ9Jv+BfTQfsJiQ0R2z+SRm5kzZ2LgwIGoUqUKhBAICgrKPWT08ccfm7Su0aNH45133kGTJk3QokULfPvtt0hOTkZoaCiAvw4pXb9+HStWrECxYsVQr149g+UrVKgAd3f3PNPJdKkxq+H/9NnIAemFBp/r+uBbfVfwaigicgQmlxsXFxesWrUK06dPR2xsLFRVRaNGjVCzZk2TNx4SEoLbt29j+vTpSElJQb169bBt2zb4+fkBAFJSUp56zxsyAyHw3I3fZKcgCdKFF0YqI3FIrSs7ChGR2WiEECY9+jk6Ohpt2rSxVB6Ly8zMhLe3NzIyMuDlxacYA8CF2H2o+Us32THIyk6oARimHYVUlJUdhYgcSLWyntg7rq3Z12vK57fJ59x07NgRzz33HMaPH4/Tp08XOiTZjttH1siOQFb2g64jQrSTWWyIyCGZXG5u3LiBDz74APv370f9+vVRv359zJ49G9eu8WRUeyRUPaql7pAdg6zkkXBFhHYopugGQeFl3kTkoEwuN+XKlcOIESNw8OBBJCYmIiQkBCtWrEC1atXyvRSbbNu5Y7tQEemyY5AVXFEr4HXtNGxUW8uOQkRkUc/0Xzd/f3+MHz8eDRo0wKRJkxAdHW2uXGQlGUcjZUcgK9ipb4TRylBkooTsKEREFlfop4IfPHgQw4YNQ6VKldC3b1/UrVsXv/76qzmzkYWpOh1q3NopOwZZkCo0+EJ5C+8rY1hsiKjIMHnk5qOPPsKaNWtw48YNdOjQAfPnz0fPnj3h6elpiXxkQfFHfkM93JMdgyzkriiBUcpw7FMbyI5CRGRVJpebvXv3YuzYsQgJCUG5cuUskYms5OHxdbIjkIWcVP0xTAnHNVFedhQiIqszudzExMRYIgdZmU6bg5p39siOQRawRtcWU3UDkANX2VGIiKQwqtxs3rwZXbp0gYuLCzZv3vzEebt3726WYGRZ8TG/oj6yZMcgM8oRLpisG4hIvflvnkVEZE+MKjc9e/ZEamoqKlSogJ49exY4n0ajgV6vN1c2sqCcuJ9kRyAzuibKIVQbjtOiuuwoRETSGVVuVFXN989kn7TZj1D7Hi/bdxTR+voYpQzHPZSUHYWIyCaYfCn4ihUrkJOTk2e6VqvFihUrzBKKLCt+/0Z44aHsGGQGC3S9MEj5gMWGiOhvTC43gwYNQkZGRp7pWVlZGDRokFlCkWXpTv0sOwI9o0zhiXe1YzFP9xbUwt+uiojIIZl8tZQQAhqNJs/0a9euwdvb2yyhyHKyH2YhKGM/kPevkOxEvOqHUCUcycJHdhQiIptkdLlp1KgRNBoNNBoN2rdvD2fn/y2q1+uRlJSEV155xSIhyXzio9ejsSbvYUWyDz/rX8REZTCy4SY7ChGRzTK63Dy+SiouLg6dO3dGiRL/u5W7q6srqlWrhjfeeMPsAcnMzmyQnYAKQSucMF3XHyv1HcBhNyKiJzO63EyZMgUAUK1aNYSEhMDd3d1iocgyHmTeRVDWIX422pkUUQbDtWE4IWrJjkJEZBdMPudmwIABlshBVnA2OhLBGkV2DDJBjD4II5WRuA2ez0ZEZCyTy41er8e8efOwbt06JCcnQ6vVGrx/584ds4Uj83JK2CQ7ApngG103/EfXG3o4yY5CRGRXTL6GdNq0aZg7dy569+6NjIwMjB49Gq+//jqKFSuGqVOnWiAimUPG3VsIevCH7BhkhCzhgVBtOD7Tvc1iQ0RUCCaXm1WrVuG7777D2LFj4ezsjLfffhvff/89Jk+ejMOHD1siI5nB+b1r4KrhozFs3Xm1CnpoP8F2tansKEREdsvkcpOamornn38eAFCiRIncG/p17doVW7duNW86Mhu3c7/IjkBPsUXfHD21n+CSqCw7ChGRXTO53FStWhUpKSkAgICAAOzYsQMAcPToUbi58d4btujurRsIenRCdgwqgE4Uw3TlHYxURuIheBUiEdGzMrnc9OrVC7t27QIAjBo1CpMmTULNmjXRv39/vPvuu2YPSM/u/N7VcNbwgae2KE2Uwtvaj7FU3wW8Rp+IyDxMvlrqs88+y/3zm2++iapVqyImJgYBAQHo3r27WcOReZS4wENStugPtTaGa8NwC6VlRyEicigml5t/at68OZo3b26OLGQB6SlXEJhzioMCNmaJrgtm6d6G7tn/CRIR0T8Y9Zt18+bNRq+Qoze2JXHvSpTTCNkx6P89FG74UHkfW9SWsqMQETkso8rN4+dKPY1Go4Fez8uNbYn3pV9lR6D/l6hWQqgSgQuiquwoREQOzahyo6o8GdUe3Uy+gDpKvOwYBGC7/gWMVYbgPjxlRyEicng84O/Akvatgo/sEEWcXmgwW9cH/9V3BU98IiKyDpPLzfTp05/4/uTJkwsdhsyr7GUekpLptiiJEUoYDql1ZUchIipSTC43GzduNHitKAqSkpLg7OyMGjVqsNzYiOuJp1FTd0F2jCIrTq2BodpwpKCs7ChEREWOyeUmNjY2z7TMzEwMHDgQvXr1MksoenZX969GFdkhiqgfdR3wie4daOEiOwoRUZFk8h2K8+Pl5YXp06dj0qRJ5lgdmYFPMp/zZW3ZwgVjtKGYpHuXxYaISCKznVB879693IdoklxXzh6Hv3pZdowiJVktj1AlAvGimuwoRERFnsnlZuHChQavhRBISUnBjz/+iFdeecVswajwUg6uhp/sEEXILn0jRChDkYkSsqMQEREKUW7mzZtn8LpYsWIoX748BgwYgAkTJpgtGBWSEKh8/TfZKYoEVWgwT/cGvtL3hDDPEV4iIjIDk8tNUlKSJXKQmSSeOowa6nXZMRzePVEco5QRiFYbyI5CRET/wJv4OZi0w6tRQ3YIB3dKrYahSjiuiQqyoxARUT5MLjfZ2dn48ssvsWfPHqSlpeV5NMOJEyfMFo5MJAT8UrbLTuHQ1unaYJJuEHLgKjsKEREVwORy8+677yIqKgpvvvkmmjZtCo2Gt5S3Fedjo1FLpMmO4ZByhDMm6wYhUt9WdhQiInoKk8vN1q1bsW3bNrRq1coSeegZ3DmyVnYEh3RNlMMw7SicFDzgR0RkD0wuN1WqVEHJkiUtkYWegVD1qH7zd9kxHM4+/fMYpQzHXXjJjkJEREYy+frVOXPm4MMPP8SVK1cskYcK6ezRnaiAO7JjOJQvdT0xUPmQxYaIyM6YPHLTpEkTZGdno3r16vD09ISLi+Ft5u/c4QesDJlHeUjKXDKFJyKUodilBsuOQkREhWByuXn77bdx/fp1fPrpp/Dx8eEJxTZA1ekQkL5bdgyHkKD6IlSJwBVRUXYUIiIqJJPLTUxMDA4dOoQGDXjzMluRcGgr6uKe7Bh2b4P+RXykDEY23GRHISKiZ2ByualTpw4ePXpkiSxUSA9if5Idwa5phRM+0b2DH/UdAXAkkojI3pl8QvFnn32GMWPGYO/evbh9+zYyMzMNvsi6dNoc1LqzR3YMu5UqSqOPdhJ+1HcCiw0RkWMweeTm8ZO/27dvbzBdCAGNRgO9Xm+eZGSUMwc3owHuy45hlw7pgzBSGYl0eMuOQkREZmRyudmzh6MEtkQbx0NShfGNriv+owuBHk6yoxARkZmZXG7atGljiRxUCDnZD1AnY5/sGHblvnDHWCUU29WmsqMQEZGFmFxu9u178ofpSy+9VOgwZJr4fRvRCDy521gX1CoIVcKRKKrIjkJERBZkcrl5+eWX80z7+71ueM6N9ainfpYdwW78qm+OD5R/4yHcZUchIiILM/lqqbt37xp8paWlYfv27XjhhRewY8cOS2SkfDy6n4nAzIOyY9g8nSiGT5R/YYQyksWGiKiIMHnkxts775UlHTt2hJubGyIiInD8+HGzBKMnS9i3Ho01ObJj2LRbwhvDtWH4QwTKjkJERFZkcrkpSPny5XHu3DlzrY6e5swG2Qls2lG1FoZrRyENpWVHISIiKzO53Jw8edLgtRACKSkp+Oyzz/hIBiu5n3kHde8f5j3nCrBU9wo+1fWFznzdnYiI7IjJv/0bNmwIjUYDIYTB9ObNm2Pp0qVmC0YFO7s3Ek00iuwYNuehcMN45X1sVlvKjkJERBKZXG6SkpIMXhcrVgzly5eHuztP1rQWl4SNsiPYnEtqRYQqETgvfGVHISIiyUy+WsrPz8/gy9fX95mKzaJFi+Dv7w93d3cEBwdj//79Bc67YcMGdOzYEeXLl4eXlxdatGiB33//vdDbtkcZd28h8OEx2TFsyu/6JuihncFiQ0REAEwoN7t370ZQUFC+D8fMyMhA3bp1n1hM8hMZGYnw8HBMnDgRsbGxaN26Nbp06YLk5OR859+3bx86duyIbdu24fjx42jbti26deuG2NhYk7Zrz87vWQ1XDe8lBAB6ocHnSh+EKuHIgqfsOEREZCM04p8nzxSge/fuaNu2LSIiIvJ9f+HChdizZw82bjT+kEmzZs3QuHFjLF68OHdaYGAgevbsiVmzZhm1jrp16yIkJASTJ0/O9/2cnBzk5PzvkunMzEz4+voiIyMDXl5eRme1FadmtcXzOSdkx5DutiiJkcpIxKj1ZEchIqK/qVbWE3vHtTX7ejMzM+Ht7W3U57fRIzd//vln7hPB89OpUyeT7nGj1Wpx/PhxdOrUKc96YmJijFqHqqrIyspCmTJlCpxn1qxZ8Pb2zv3y9bXfQxd3bl5DYHac7BjSxak10DXnUxYbIiLKl9Hl5ubNm3BxcSnwfWdnZ9y6dcvoDaenp0Ov18PHx8dguo+PD1JTU41ax5w5c/DgwQP07t27wHkmTJiAjIyM3K+rV68andHWXIheDWeNKjuGVCt17dFbOxkpKCs7ChER2Sijr5aqUqUKTp06hYCAgHzfP3nyJCpVqmRygL8/lwr46745/5yWnzVr1mDq1Kn45ZdfUKFChQLnc3Nzg5ubm8m5bFGJi5tlR5AmW7jgY927WK/nU+mJiOjJjB65efXVVzF58mRkZ2fnee/Ro0eYMmUKunbtavSGy5UrBycnpzyjNGlpaXlGc/4pMjISgwcPxrp169ChQwejt2nP0m9cRmDOadkxpEhWy+N17TQWGyIiMorR5ebjjz/GnTt3UKtWLcyePRu//PILNm/ejM8//xy1a9fGnTt3MHHiRKM37OrqiuDgYERFRRlMj4qKQsuWBd+Ebc2aNRg4cCBWr16N1157zejt2buLe1eimMaoc78dym59Q3TVzkS8qCY7ChER2QmjD0v5+PggJiYGQ4cOxYQJE3LvUKzRaNC5c2csWrToqSMu/zR69Gi88847aNKkCVq0aIFvv/0WycnJCA0NBfDX+TLXr1/HihUrAPxVbPr3748FCxagefPmuaM+Hh4e+T7Q05GUvrRFdgSrUoUG83Vv4Et9TwjTb8dERERFmEl3KPbz88O2bdtw9+5dXLx4EUII1KxZE6VLF+7hhCEhIbh9+zamT5+OlJQU1KtXD9u2bYOfnx8AICUlxeCeN//973+h0+kwfPhwDB8+PHf6gAEDsHz58kJlsAepyedRW3dWdgyruSeKI1wZjr1qQ9lRiIjIDhl9nxtHYcp18rbi8I+T0TxxgewYVnFarYZQJRzXRMEniRMRke2yhfvc8LHJdqDc5V9lR7CKdbo2mKQbhBy4yo5CRER2jOXGxl27eAoB+kTZMSwqRzhjqm4A1ujbAXj6bQCIiIiehOXGxl3bvxJVZYewoOuiLIZqw3FS1JAdhYiIHATLjY3zufqb7AgWs19fD2HKCNyFfZz7RERE9oHlxoZdSTgGf/WK7BgW8ZWuB+bq3oLKy7yJiMjMWG5sWMrB1fCTHcLMMoUHxihDEaU2kR2FiIgcFMuNrRICVa471iGps6ovQpVwXBamP4OMiIjIWCw3NirxVAxqiBuyY5jNJn1LTFDewyO4y45CREQOjuXGRqUdWgtHuH5IEU6YofsXftB3Ai/zJiIia2C5sUVCwC91u+wUz+ymKIVh2lE4LmrLjkJEREUIy40NOnd8D2qLNNkxnskRtQ5GaMNwC6VkRyEioiKG5cYG3f1jrewIz+Rb3WuYrQuBjj9eREQkAT99bIxQ9aieFiU7RqE8EG4YpwzBNrW57ChERFSEsdzYmLNHdiAQd2THMNlFtTKGKBFIFFVkRyEioiKO5cbGZB5fJzuCybbqm+IDZQgewEN2FCIiIpYbW6LXKQhI3yU7htF0ohg+1/XBd/rXwMu8iYjIVrDc2JCEQ9tQDxmyYxjllvDCSCUMh9Ug2VGIiIgMsNzYkIcn7OOQ1HG1JoZpR+EmysiOQkRElAfLjY1QtNmofXeP7BhPtUzXGZ/q+kHhjw4REdkofkLZiPgDm9EAD2THKNAj4Yrxynv4RX1RdhQiIqInYrmxEdo/f5IdoUBJqg+GKhE4K56THYWIiOipWG5sQE72AwTe22+TFxxF6YMxRglFJorLjkJERGQUlhsbEL9vAxppHsmOYUAvNJij643F+m4QKCY7DhERkdFYbmyAeupn2REM3BElEKaMxAH1edlRiIiITMZyI9mj+5kIzIyxmUNSf6rVMVQbjhsoJzsKERFRofB4g2Tx+9bBU5MjOwYAYLWuHXprJ7PYEBGRXePIjWTFzmyUHQE5wgUf6wbhJ/3LsqMQERE9M5Ybie5n3kHQ/SNSD0ldVcsjVAnHGeEvLwQREZEZ8bCURAl71sJNo0jb/l59A3TTzmCxISIih8KRG4lcz8o7JDVf9zoW6l6Hyn5LREQOhuVGkszbaQh6eNzqh6QyhCfCleHYozay7oaJiIishP9tl+Tc3lVw0eitus141Q9dtTNZbIiIyKFx5EYSj/O/WHV76/Uv4WNlELLhZtXtEhERWRvLjQR3bl5DYHacVQ5JaYUTpuoGYrW+HWzmToFEREQWxHIjwYXoVWimERbfzg1RBsO04YgTARbfFhERka1guZGg5MUtFt/GQX1djFRG4g68LL4tIiIiW8JyY2W3riehTs5pix4hWqTrjjm6t6CHk+U2QkREZKNYbqwsMXolylvokFSm8MBYJRQ71Bcssn4iIiJ7wHJjZaUvWeaQ1Dm1KkKVCCSJShZZPxERkb1gubGiG0lnUVt3zuzr/UXfEhOU9/AQ7mZfNxERkb1hubGi5P2rUNmM61OEE2bq+mG5vjN4mTcREdFfWG6sqNyVrWZb101RCsO0o3Bc1DbbOomIiBwBy42VXL1wEgH6RLOs64haByO0YbiFUmZZHxERkSNhubGS6wdWwdcM6/lO9yo+1/WBjn91RERE+eInpJVUvLrtmZZ/INzwgTIEW9XmZkpERETkmFhurOBy/FFUU5MLvXyiWglDlAhcFFXNmIqIiMgxFZMdoChIiVld6GV/07+AHtpPWGyIiIiMxJEbSxMCvtd/M3kxvdDgc10ffKvvCl7mTUREZDyWGwu7ePIgAkSKScukCy+MVEbikFrXQqmIiIgcF8uNhaUfXo0AE+Y/oQZgmHYUUlHWYpmIiIgcGcuNJQkBv9QdRs/+g64jZujegcK/FiIiokLjp6gFnT2+G3XErafO90i44iNlMDaqra2QioiIyLGx3FjQvT/WPnWey6oPQpUInBXPWSERERGR42O5sRBVp0ONtKgnzrNT3wijlWHIRHErpSIiInJ8LDcWcvaPHQjC3XzfU4UGc3Vv4mt9DwjeaoiIiMisWG4sJOt4ZL7T74oSGKUMxz61gZUTERERFQ0sNxag1ymoeXt3nuknVX8MU8JxTZSXkIqIiKhoYLmxgPiYX/E8Mg2mrdG1xVTdAOTAVVIqIiKiooHlxgKyT/yU++cc4YLJuoGI1LeVmIiIiKjokH4266JFi+Dv7w93d3cEBwdj//79T5w/OjoawcHBcHd3R/Xq1fHNN99YKalxFG02at/bCwC4JsrhDe0UFhsiIiIrklpuIiMjER4ejokTJyI2NhatW7dGly5dkJycnO/8SUlJePXVV9G6dWvExsbio48+QlhYGH7++WcrJy9Y/IFN8MIDROvro2vOTJwW1WVHIiIiKlI0Qggha+PNmjVD48aNsXjx4txpgYGB6NmzJ2bNmpVn/g8//BCbN29GQkJC7rTQ0FD8+eefOHTokFHbzMzMhLe3NzIyMuDl5fXs38Q/HJ3XGzG3PbFA9wZU+QNjREREVlWtrCf2jjP/EQtTPr+lnXOj1Wpx/PhxjB8/3mB6p06dEBMTk+8yhw4dQqdOnQymde7cGUuWLIGiKHBxccmzTE5ODnJycnJfZ2RkAPhrJ5mdENjp/DLiKtbBC+ZfOxERkc3zKelqkc/Yx+s0ZkxGWrlJT0+HXq+Hj4+PwXQfHx+kpqbmu0xqamq+8+t0OqSnp6NSpUp5lpk1axamTZuWZ7qvr+8zpCciIqKCfDnQcuvOysqCt7f3E+eRfrWURqMxeC2EyDPtafPnN/2xCRMmYPTo0bmvVVXFnTt3ULZs2SdupzAyMzPh6+uLq1evWuSQF/2F+9k6uJ+tg/vZerivrcNS+1kIgaysLFSuXPmp80orN+XKlYOTk1OeUZq0tLQ8ozOPVaxYMd/5nZ2dUbZs2XyXcXNzg5ubm8G0UqVKFT64Eby8vPgPxwq4n62D+9k6uJ+th/vaOiyxn582YvOYtDNeXV1dERwcjKgow4dLRkVFoWXLlvku06JFizzz79ixA02aNMn3fBsiIiIqeqRezjN69Gh8//33WLp0KRISEhAREYHk5GSEhoYC+OuQUv/+/XPnDw0NxZUrVzB69GgkJCRg6dKlWLJkCcaOHSvrWyAiIiIbI/Wcm5CQENy+fRvTp09HSkoK6tWrh23btsHPzw8AkJKSYnDPG39/f2zbtg0RERH4+uuvUblyZSxcuBBvvPGGrG/BgJubG6ZMmZLnMBiZF/ezdXA/Wwf3s/VwX1uHLexnqfe5ISIiIjI33mWOiIiIHArLDRERETkUlhsiIiJyKCw3RERE5FBYbky0aNEi+Pv7w93dHcHBwdi/f/8T54+OjkZwcDDc3d1RvXp1fPPNN1ZKat9M2c8bNmxAx44dUb58eXh5eaFFixb4/fffrZjWfpn68/zYwYMH4ezsjIYNG1o2oIMwdT/n5ORg4sSJ8PPzg5ubG2rUqIGlS5daKa39MnU/r1q1Cg0aNICnpycqVaqEQYMG4fbt21ZKa5/27duHbt26oXLlytBoNNi0adNTl5HyOSjIaGvXrhUuLi7iu+++E/Hx8WLUqFGiePHi4sqVK/nOf+nSJeHp6SlGjRol4uPjxXfffSdcXFzE+vXrrZzcvpi6n0eNGiU+//xz8ccff4jz58+LCRMmCBcXF3HixAkrJ7cvpu7nx+7duyeqV68uOnXqJBo0aGCdsHasMPu5e/fuolmzZiIqKkokJSWJI0eOiIMHD1oxtf0xdT/v379fFCtWTCxYsEBcunRJ7N+/X9StW1f07NnTysnty7Zt28TEiRPFzz//LACIjRs3PnF+WZ+DLDcmaNq0qQgNDTWYVqdOHTF+/Ph85//ggw9EnTp1DKYNGTJENG/e3GIZHYGp+zk/QUFBYtq0aeaO5lAKu59DQkLExx9/LKZMmcJyYwRT9/Nvv/0mvL29xe3bt60Rz2GYup//85//iOrVqxtMW7hwoahatarFMjoaY8qNrM9BHpYyklarxfHjx9GpUyeD6Z06dUJMTEy+yxw6dCjP/J07d8axY8egKIrFstqzwuznf1JVFVlZWShTpowlIjqEwu7nZcuWITExEVOmTLF0RIdQmP28efNmNGnSBLNnz0aVKlVQq1YtjB07Fo8ePbJGZLtUmP3csmVLXLt2Ddu2bYMQAjdv3sT69evx2muvWSNykSHrc1D6U8HtRXp6OvR6fZ6Hevr4+OR5mOdjqamp+c6v0+mQnp6OSpUqWSyvvSrMfv6nOXPm4MGDB+jdu7clIjqEwuznCxcuYPz48di/fz+cnfmrwxiF2c+XLl3CgQMH4O7ujo0bNyI9PR3Dhg3DnTt3eN5NAQqzn1u2bIlVq1YhJCQE2dnZ0Ol06N69O7788ktrRC4yZH0OcuTGRBqNxuC1ECLPtKfNn990MmTqfn5szZo1mDp1KiIjI1GhQgVLxXMYxu5nvV6Pvn37Ytq0aahVq5a14jkMU36eVVWFRqPBqlWr0LRpU7z66quYO3culi9fztGbpzBlP8fHxyMsLAyTJ0/G8ePHsX37diQlJeU+25DMR8bnIP/7ZaRy5crByckpz/8C0tLS8rTSxypWrJjv/M7OzihbtqzFstqzwuznxyIjIzF48GD89NNP6NChgyVj2j1T93NWVhaOHTuG2NhYjBgxAsBfH8JCCDg7O2PHjh1o166dVbLbk8L8PFeqVAlVqlSBt7d37rTAwEAIIXDt2jXUrFnTopntUWH286xZs9CqVSuMGzcOAFC/fn0UL14crVu3xowZMziybiayPgc5cmMkV1dXBAcHIyoqymB6VFQUWrZsme8yLVq0yDP/jh070KRJE7i4uFgsqz0rzH4G/hqxGThwIFavXs1j5kYwdT97eXnh1KlTiIuLy/0KDQ1F7dq1ERcXh2bNmlkrul0pzM9zq1atcOPGDdy/fz932vnz51GsWDFUrVrVonntVWH288OHD1GsmOFHoJOTE4D/jSzQs5P2OWjR05UdzONLDZcsWSLi4+NFeHi4KF68uLh8+bIQQojx48eLd955J3f+x5fARUREiPj4eLFkyRJeCm4EU/fz6tWrhbOzs/j6669FSkpK7te9e/dkfQt2wdT9/E+8Wso4pu7nrKwsUbVqVfHmm2+KM2fOiOjoaFGzZk3x3nvvyfoW7IKp+3nZsmXC2dlZLFq0SCQmJooDBw6IJk2aiKZNm8r6FuxCVlaWiI2NFbGxsQKAmDt3roiNjc295N5WPgdZbkz09ddfCz8/P+Hq6ioaN24soqOjc98bMGCAaNOmjcH8e/fuFY0aNRKurq6iWrVqYvHixVZObJ9M2c9t2rQRAPJ8DRgwwPrB7YypP89/x3JjPFP3c0JCgujQoYPw8PAQVatWFaNHjxYPHz60cmr7Y+p+XrhwoQgKChIeHh6iUqVKol+/fuLatWtWTm1f9uzZ88Tft7byOagRguNvRERE5Dh4zg0RERE5FJYbIiIicigsN0RERORQWG6IiIjIobDcEBERkUNhuSEiIiKHwnJDREREDoXlhoiIiBwKyw2RHdNoNNi0aZPNrOdZ7N27FxqNBvfu3ZOawxSpqano2LEjihcvjlKlSsmOg+XLlxvkmDp1Kho2bPhM6zTHOoisjeWG6AlSU1MxcuRIVK9eHW5ubvD19UW3bt2wa9cu2dEKpaAPqpSUFHTp0sWi246NjUXXrl1RoUIFuLu7o1q1aggJCUF6erpFt2tJ8+bNQ0pKCuLi4nD+/Pl855k6dSo0Gg00Gg2cnJzg6+uL9957D7du3bJ4vrFjx5r0s5pfyTV1HUS2wFl2ACJbdfnyZbRq1QqlSpXC7NmzUb9+fSiKgt9//x3Dhw/H2bNnZUc0m4oVK1p0/WlpaejQoQO6deuG33//HaVKlUJSUhI2b96Mhw8fWnTbWq0Wrq6uFll3YmIigoODUbNmzSfOV7duXezcuRN6vR6xsbEYPHgwrl+/jt9++y3PvHq9HhqNJs8TqwujRIkSKFGihPR1EFmdxZ9eRWSnunTpIqpUqSLu37+f5727d+8KIYRISkoSAERsbKzBewDEnj17hBD/e9Dc9u3bRcOGDYW7u7to27atuHnzpti2bZuoU6eOKFmypOjTp4948OBB7nr8/PzEvHnzDLbboEEDMWXKlNzXAMTGjRtzX3/wwQeiZs2awsPDQ/j7+4uPP/5YaLVaIcRfT0HGPx52t2zZsjzrad68ufjwww8NtpuWliacnZ3F7t27hRBC5OTkiHHjxonKlSsLT09P0bRp09zvNz8bN24Uzs7OQlGUAud5vJ927twpgoODhYeHh2jRooU4e/Zs7jwXL14U3bt3FxUqVBDFixcXTZo0EVFRUQbr8fPzE5988okYMGCA8PLyEv379xdCCHHw4EHRunVr4e7uLqpWrSpGjhyZ79/t3y1atEhUr15duLi4iFq1aokVK1YYbAdGPKg1vweMzpgxQxQrVkw8fPhQLFu2THh7e4stW7aIwMBA4eTkJC5dumTUPl62bJnw9fUVHh4eomfPnuKLL74Q3t7eT9z2kiVLRFBQkHB1dRUVK1YUw4cPz/f78fPzy3cder1eTJs2TVSpUkW4urqKBg0aiN9++y33/cf/Jn7++Wfx8ssvCw8PD1G/fn0RExOTO8/ly5dF165dRalSpYSnp6cICgoSW7dufeLfBZEpeFiKKB937tzB9u3bMXz4cBQvXjzP+4U5v2Lq1Kn46quvEBMTg6tXr6J3796YP38+Vq9eja1btyIqKgpffvnlM+UuWbIkli9fjvj4eCxYsADfffcd5s2bBwAICQnBmDFjULduXaSkpCAlJQUhISF51tGvXz+sWbMG4m/P1I2MjISPjw/atGkDABg0aBAOHjyItWvX4uTJk3jrrbfwyiuv4MKFC/nmqlixInQ6HTZu3Giw3vxMnDgRc+bMwbFjx+Ds7Ix3330397379+/j1Vdfxc6dOxEbG4vOnTujW7duSE5ONljHf/7zH9SrVw/Hjx/HpEmTcOrUKXTu3Bmvv/46Tp48icjISBw4cAAjRowoMMfGjRsxatQojBkzBqdPn8aQIUMwaNAg7NmzBwBw9OhRvPLKK+jduzdSUlKwYMGCJ35ff+fh4QFVVaHT6QAADx8+xKxZs/D999/jzJkzqFChwlP38ZEjR/Duu+9i2LBhiIuLQ9u2bTFjxownbnfx4sUYPnw4/v3vf+PUqVPYvHkzAgICcr8fAFi2bBlSUlJyX//TggULMGfOHHzxxRc4efIkOnfujO7du+f5u584cSLGjh2LuLg41KpVC2+//Xbu9zt8+HDk5ORg3759OHXqFD7//HOODpF5yW5XRLboyJEjAoDYsGHDE+czZeRm586dufPMmjVLABCJiYm504YMGSI6d+6c+7owIzf/NHv2bBEcHJz7Or//yf9zPY9Hafbt25f7fosWLcS4ceOEEH+Nnmg0GnH9+nWDdbRv315MmDChwCwfffSRcHZ2FmXKlBGvvPKKmD17tkhNTc19P7/9tHXrVgFAPHr0qMD1BgUFiS+//DL3tZ+fn+jZs6fBPO+8847497//bTBt//79olixYgWuu2XLluL99983mPbWW2+JV199Nfd1jx49Chyxeeyf+zwhIUEEBASIpk2bCiH+N6IWFxeXO48x+/jtt98Wr7zyisH7ISEhTxy5qVy5spg4cWKBWfP7ecpvHTNnzjSY54UXXhDDhg0TQvzv38T333+f+/6ZM2cEAJGQkCCEEOL5558XU6dOLTAH0bPiyA1RPsT/jy5oNBqzrbN+/fq5f/bx8YGnpyeqV69uMC0tLe2ZtrF+/Xq8+OKLqFixIkqUKIFJkyblGdV4mvLly6Njx45YtWoVACApKQmHDh1Cv379AAAnTpyAEAK1atXKPR+jRIkSiI6ORmJiYoHrnTlzJlJTU/HNN98gKCgI33zzDerUqYNTp04ZzPf3/VSpUiUAyN0vDx48wAcffICgoCCUKlUKJUqUwNmzZ/N8j02aNDF4ffz4cSxfvtwgb+fOnaGqKpKSkvLNm5CQgFatWhlMa9WqFRISEgr8Hgty6tQplChRAh4eHggKCoKvr2/u/gUAV1dXg+/bmH2ckJCAFi1aGGznn6//Li0tDTdu3ED79u1Nzv9YZmYmbty4YdR+edLfY1hYGGbMmIFWrVphypQpOHnyZKEzEeWHJxQT5aNmzZrQaDRISEhAz549C5zv8Umf4m+HWhRFyXdeFxeX3D9rNBqD14+nqapqsG7xj0M4Ba0bAA4fPow+ffpg2rRp6Ny5M7y9vbF27VrMmTOnwGUK0q9fP4waNQpffvklVq9ejbp166JBgwYAAFVV4eTkhOPHj8PJyclguacdWihbtizeeustvPXWW5g1axYaNWqEL774Aj/88EPuPP/cT4+3CQDjxo3D77//ji+++AIBAQHw8PDAm2++Ca1Wa7Cdfx5KVFUVQ4YMQVhYWJ5Mzz33XIF5/1luhRCFKry1a9fG5s2b4eTkhMqVK8PNzc3gfQ8PD4P1GrOP//mz8TQeHh4m5y6IMfvlSX+P7733Hjp37oytW7dix44dmDVrFubMmYORI0eaLSMVbRy5IcpHmTJl0LlzZ3z99dd48OBBnvcf34ulfPnyAP66lPqxuLg4s2QoX768wXozMzMLHGUAgIMHD8LPzw8TJ05EkyZNULNmTVy5csVgHldXV+j1+qduu2fPnsjOzsb27duxevVq/Otf/8p9r1GjRtDr9UhLS0NAQIDBlylXXbm6uqJGjRr57t+C7N+/HwMHDkSvXr3w/PPPo2LFirh8+fJTl2vcuDHOnDmTJ29AQECBV1IFBgbiwIEDBtNiYmIQGBhodN7HXF1dERAQAH9//zzFJj/G7OOgoCAcPnzYYLl/vv67kiVLolq1ak+8rNvFxeWJPx9eXl6oXLmyWfaLr68vQkNDsWHDBowZMwbfffedScsTPQlHbogKsGjRIrRs2RJNmzbF9OnTUb9+feh0OkRFRWHx4sVISEiAh4cHmjdvjs8++wzVqlVDeno6Pv74Y7Nsv127dli+fDm6deuG0qVLY9KkSXn+F/93AQEBSE5Oxtq1a/HCCy9g69at2Lhxo8E81apVQ1JSEuLi4lC1alWULFky3w/b4sWLo0ePHpg0aRISEhLQt2/f3Pdq1aqFfv36oX///pgzZw4aNWqE9PR07N69G88//zxeffXVPOv79ddfsXbtWvTp0we1atWCEAJbtmzBtm3bsGzZMqP3SUBAADZs2IBu3bpBo9Fg0qRJBqNdBfnwww/RvHlzDB8+HO+//z6KFy+OhISEJ57EPW7cOPTu3RuNGzdG+/btsWXLFmzYsAE7d+40Om9hGbOPw8LC0LJlS8yePRs9e/bEjh07sH379ieud+rUqQgNDUWFChXQpUsXZGVl4eDBg7kjJo/LT6tWreDm5obSpUvnWce4ceMwZcoU1KhRAw0bNsSyZcsQFxdncJjtacLDw9GlSxfUqlULd+/exe7duwtVGokKJO1sHyI7cOPGDTF8+HDh5+cnXF1dRZUqVUT37t0NLsmNj48XzZs3Fx4eHqJhw4Zix44d+Z5Q/PjycSFE7uW/f/fPEzczMjJE7969hZeXl/D19RXLly9/6gnF48aNE2XLlhUlSpQQISEhYt68eQbbyc7OFm+88YYoVapUgZeCP/b4ZN6XXnopz37RarVi8uTJolq1asLFxUVUrFhR9OrVS5w8eTLf/ZiYmCjef/99UatWLeHh4SFKlSolXnjhhdztF7SfYmNjBQCRlJQkhPjrZNW2bdsKDw8P4evrK7766ivRpk0bMWrUqNxl8jsRWwgh/vjjD9GxY0dRokQJUbx4cVG/fv08J8b+05MuBReicCcU/1N+PwtCGLePlyxZIqpWrSo8PDxEt27djLoU/JtvvhG1a9cWLi4uolKlSmLkyJG5723evFkEBAQIZ2dnoy4Fd3FxKfBS8CedZD9ixAhRo0YN4ebmJsqXLy/eeecdkZ6eXuA+IjKVRggTD9wSERER2TCec0NEREQOheWGiIiIHArLDRERETkUlhsiIiJyKCw3RERE5FBYboiIiMihsNwQERGRQ2G5ISIiIofCckNEREQOheWGiIiIHArLDRERETmU/wM+m7xHR0GoUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cumulative_actual_shares = cumulative_actual / sum(actual)\n",
    "cumulative_index_shares = cumulative_index / len(predictions)\n",
    "\n",
    "# Add (0, 0) to the plot\n",
    "x_values = [0] + list(cumulative_index_shares)\n",
    "y_values = [0] + list(cumulative_actual_shares)\n",
    "\n",
    "# Display the 45° line stacked on top of the y values\n",
    "diagonal = [(x - y) for (x, y) in zip(x_values, y_values)]\n",
    "#diagonal.reverse()\n",
    "plt.stackplot(x_values, y_values, diagonal)\n",
    "plt.xlabel('Cumulative Share of Predictions')\n",
    "plt.ylabel('Cumulative Share of Actual Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172240b",
   "metadata": {
    "papermill": {
     "duration": 0.014812,
     "end_time": "2023-02-27T12:45:39.287704",
     "exception": false,
     "start_time": "2023-02-27T12:45:39.272892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Step 3: Weighted Gini Coefficient:  Calculate the reference line. Is it always a straight diagonal line?\n",
    "\n",
    "If the distribution of positive and negative instances in the dataset is not random, then the diagonal line that represents perfect equality in the Lorenz curve may not be the appropriate reference line to use for calculating the Gini coefficient. In such cases, a different reference line may be used that represents the expected distribution of positive and negative instances based on prior knowledge or assumptions.\n",
    "\n",
    "For example, if it is known that the proportion of positive instances in the population is 10%, then a reference line that represents this distribution can be used instead of the diagonal line. Similarly, if the dataset has been sampled from a stratified population with known proportions of positive and negative instances in each stratum, then a reference line that reflects these proportions can be used.\n",
    "\n",
    "The Gini coefficient can still be calculated using the same formula, where A is the area under the reference line and B is the area between the Lorenz curve and the reference line. The choice of reference line depends on the specific context and assumptions of the problem, and may require some prior knowledge or domain expertise. It's important to note that the Gini coefficient is not necessarily sensitive to the choice of reference line, as long as the same reference line is used consistently across different models or datasets for comparability.\n",
    "\n",
    "***Why do we create a reference line using instance weights instead of the typical random line in the Gini coefficient calculation?***\n",
    "\n",
    "We create a reference line using instance weights in the weighted Gini coefficient calculation because it allows us to take into account the imbalance in the dataset and to compare the performance of the model against a baseline that reflects this imbalance.\n",
    "\n",
    "In a binary classification problem with an imbalanced dataset, the random line in the Lorenz curve would not be an appropriate baseline because it assumes that the positive and negative classes are equally important and have equal weights. This is not the case in an imbalanced dataset where the positive class is often more rare and more important than the negative class. For example, in a medical diagnosis problem, the positive class may represent a rare disease that requires urgent treatment, while the negative class represents the absence of the disease, which may not be as critical.\n",
    "\n",
    "By creating a reference line using the instance weights, we can define a baseline that reflects the importance of each instance in the population and takes into account the imbalance in the dataset. This allows us to compare the performance of the model against a baseline that is more appropriate for the problem at hand and to quantify how much better the model is doing than random chance given the imbalance in the dataset.\n",
    "\n",
    "The reference line is calculated as the cumulative sum of the weights, normalized by the total weight of the dataset. Keep in mind that the instance weights should be normalized so that they sum to 1, and that the reference line should be created by calculating the cumulative proportion of class weight for each instance rank based on the instance weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47684189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:39.320359Z",
     "iopub.status.busy": "2023-02-27T12:45:39.319615Z",
     "iopub.status.idle": "2023-02-27T12:45:39.338518Z",
     "shell.execute_reply": "2023-02-27T12:45:39.337173Z"
    },
    "papermill": {
     "duration": 0.038342,
     "end_time": "2023-02-27T12:45:39.341192",
     "exception": false,
     "start_time": "2023-02-27T12:45:39.302850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>weight</th>\n",
       "      <th>cum_pos_found</th>\n",
       "      <th>lorentz</th>\n",
       "      <th>random</th>\n",
       "      <th>cumulative_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.102679</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.191964</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  prediction  weight  cum_pos_found  lorentz    random  \\\n",
       "0        1        0.90       1              1     0.25  0.004464   \n",
       "2        1        0.80       1              2     0.50  0.008929   \n",
       "6        0        0.78      20              2     0.50  0.098214   \n",
       "3        1        0.75       1              3     0.75  0.102679   \n",
       "7        0        0.70      20              3     0.75  0.191964   \n",
       "4        0        0.65      20              3     0.75  0.281250   \n",
       "5        1        0.60       1              4     1.00  0.285714   \n",
       "12       0        0.50      20              4     1.00  0.375000   \n",
       "9        0        0.40      20              4     1.00  0.464286   \n",
       "10       0        0.40      20              4     1.00  0.553571   \n",
       "1        0        0.30      20              4     1.00  0.642857   \n",
       "13       0        0.10      20              4     1.00  0.732143   \n",
       "14       0        0.10      20              4     1.00  0.821429   \n",
       "8        0        0.05      20              4     1.00  0.910714   \n",
       "11       0        0.05      20              4     1.00  1.000000   \n",
       "\n",
       "    cumulative_index  \n",
       "0                  1  \n",
       "2                  3  \n",
       "6                  7  \n",
       "3                  4  \n",
       "7                  8  \n",
       "4                  5  \n",
       "5                  6  \n",
       "12                13  \n",
       "9                 10  \n",
       "10                11  \n",
       "1                  2  \n",
       "13                14  \n",
       "14                15  \n",
       "8                  9  \n",
       "11                12  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "df['cumulative_index'] = df.index + 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52787be1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:39.373840Z",
     "iopub.status.busy": "2023-02-27T12:45:39.373401Z",
     "iopub.status.idle": "2023-02-27T12:45:39.585088Z",
     "shell.execute_reply": "2023-02-27T12:45:39.583885Z"
    },
    "papermill": {
     "duration": 0.232279,
     "end_time": "2023-02-27T12:45:39.588952",
     "exception": false,
     "start_time": "2023-02-27T12:45:39.356673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cumulative_index /len(predictions), df['random'] )\n",
    "plt.xlabel('Cumulative Number of Predictions')\n",
    "plt.ylabel('Cumulative Actual Values')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68855470",
   "metadata": {
    "papermill": {
     "duration": 0.016061,
     "end_time": "2023-02-27T12:45:39.621650",
     "exception": false,
     "start_time": "2023-02-27T12:45:39.605589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Step 4: Calculate a Weighted Gini coefficient\n",
    "\n",
    "\n",
    "Calculate the area between the Lorenz curve (which represents the cumulative distribution of the predicted probabilities) and the line of perfect equality (which represents a random classifier)\n",
    "\n",
    "\n",
    "**BUT** A weighted Gini coefficient is a variation of the Gini coefficient that takes into account the different weights or importance of different observations or groups. It is often used in situations where the data is not equally distributed, and some groups or observations are more important than others.\n",
    "\n",
    "In the context of credit risk modeling, for example, the weighted Gini coefficient can be used to evaluate the performance of a model that predicts the likelihood of default for a portfolio of loans, where some loans are more valuable or riskier than others. In this case, the Gini coefficient is calculated by weighting the contribution of each loan to the overall Gini coefficient by its value or risk weight.\n",
    "\n",
    "The formula for the weighted Gini coefficient is similar to the regular Gini coefficient, but includes a weight factor:\n",
    "\n",
    "**The weighted Gini coefficient takes into account both the proportion of positive and negative instances in the dataset and the prediction performance of the model. It is calculated as the area between the ROC curve (Receiver Operating Characteristic curve) of the model and the diagonal line that represents random guessing, multiplied by a weight factor that reflects the relative importance of the positive and negative classes.**\n",
    "\n",
    "The weighted Gini coefficient is calculated by first constructing the Lorenz curve using the instance weights and the predicted class probabilities or scores from the model. Then, the Gini coefficient is calculated based on the area between the Lorenz curve and the reference line, where the reference line represents the cumulative proportion of positive class weight under the assumption of random classification.\n",
    "\n",
    "The calculation of the weighted Gini coefficient involves integrating the area between the Lorenz curve and the reference line, with the weights of each instance factored in. This means that the weighted Gini coefficient reflects the performance of the model while taking into account the importance of each instance in the population.\n",
    "\n",
    "\n",
    "The weighted Gini coefficient ranges from 0 to 1, where a value of 0 indicates perfect equality (all observations have the same weight) and a value of 1 indicates perfect inequality (one observation has all the weight)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bafcc3fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:39.656647Z",
     "iopub.status.busy": "2023-02-27T12:45:39.656237Z",
     "iopub.status.idle": "2023-02-27T12:45:39.675317Z",
     "shell.execute_reply": "2023-02-27T12:45:39.674050Z"
    },
    "papermill": {
     "duration": 0.039678,
     "end_time": "2023-02-27T12:45:39.677760",
     "exception": false,
     "start_time": "2023-02-27T12:45:39.638082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>weight</th>\n",
       "      <th>cum_pos_found</th>\n",
       "      <th>lorentz</th>\n",
       "      <th>random</th>\n",
       "      <th>cumulative_index</th>\n",
       "      <th>gini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>1</td>\n",
       "      <td>0.245536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>3</td>\n",
       "      <td>0.491071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>7</td>\n",
       "      <td>8.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.102679</td>\n",
       "      <td>4</td>\n",
       "      <td>0.647321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.191964</td>\n",
       "      <td>8</td>\n",
       "      <td>11.160714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>5</td>\n",
       "      <td>9.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>6</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>13</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>10</td>\n",
       "      <td>10.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>11</td>\n",
       "      <td>8.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>2</td>\n",
       "      <td>7.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>14</td>\n",
       "      <td>5.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>15</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>9</td>\n",
       "      <td>1.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  prediction  weight  cum_pos_found  lorentz    random  \\\n",
       "0        1        0.90       1              1     0.25  0.004464   \n",
       "2        1        0.80       1              2     0.50  0.008929   \n",
       "6        0        0.78      20              2     0.50  0.098214   \n",
       "3        1        0.75       1              3     0.75  0.102679   \n",
       "7        0        0.70      20              3     0.75  0.191964   \n",
       "4        0        0.65      20              3     0.75  0.281250   \n",
       "5        1        0.60       1              4     1.00  0.285714   \n",
       "12       0        0.50      20              4     1.00  0.375000   \n",
       "9        0        0.40      20              4     1.00  0.464286   \n",
       "10       0        0.40      20              4     1.00  0.553571   \n",
       "1        0        0.30      20              4     1.00  0.642857   \n",
       "13       0        0.10      20              4     1.00  0.732143   \n",
       "14       0        0.10      20              4     1.00  0.821429   \n",
       "8        0        0.05      20              4     1.00  0.910714   \n",
       "11       0        0.05      20              4     1.00  1.000000   \n",
       "\n",
       "    cumulative_index       gini  \n",
       "0                  1   0.245536  \n",
       "2                  3   0.491071  \n",
       "6                  7   8.035714  \n",
       "3                  4   0.647321  \n",
       "7                  8  11.160714  \n",
       "4                  5   9.375000  \n",
       "5                  6   0.714286  \n",
       "12                13  12.500000  \n",
       "9                 10  10.714286  \n",
       "10                11   8.928571  \n",
       "1                  2   7.142857  \n",
       "13                14   5.357143  \n",
       "14                15   3.571429  \n",
       "8                  9   1.785714  \n",
       "11                12   0.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42664744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:39.713360Z",
     "iopub.status.busy": "2023-02-27T12:45:39.712893Z",
     "iopub.status.idle": "2023-02-27T12:45:39.721134Z",
     "shell.execute_reply": "2023-02-27T12:45:39.719813Z"
    },
    "papermill": {
     "duration": 0.029062,
     "end_time": "2023-02-27T12:45:39.723668",
     "exception": false,
     "start_time": "2023-02-27T12:45:39.694606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.66964285714285"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gini'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b242f0",
   "metadata": {
    "papermill": {
     "duration": 0.016058,
     "end_time": "2023-02-27T12:45:39.756293",
     "exception": false,
     "start_time": "2023-02-27T12:45:39.740235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Step 5: Normalize\n",
    "\n",
    "Finally, normalize the actual Gini coefficient by dividing it by the maximum possible Gini coefficient:\n",
    "\n",
    "normalized Gini coefficient = G / G_max\n",
    "\n",
    "A higher normalized Gini coefficient indicates a better performance of the model in discriminating between the positive and negative classes, taking into account the relative importance of each class.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3527b1a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-27T12:45:39.791596Z",
     "iopub.status.busy": "2023-02-27T12:45:39.791182Z",
     "iopub.status.idle": "2023-02-27T12:45:39.805495Z",
     "shell.execute_reply": "2023-02-27T12:45:39.804287Z"
    },
    "papermill": {
     "duration": 0.035088,
     "end_time": "2023-02-27T12:45:39.808289",
     "exception": false,
     "start_time": "2023-02-27T12:45:39.773201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code Provided by the competition hosts\n",
    "# This is a python version of the metric for the Amex competition.\n",
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        \n",
    "        # Instead of going through the population from poorest to richest, we go through our predictions from lowest to highest.?? (other way round)\n",
    "        # Sort the actual values by the predictions\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        \n",
    "        # We assign the weight to the majority class (0) that we subsample\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        \n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        \n",
    "        # Sum up the targets\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        \n",
    "         # Instead of summing up the income, we sum up the actual values of our predictions:\n",
    "        # Sum up the actual values\n",
    "        # This corresponds to the Lorenz Curve\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        \n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6351662d",
   "metadata": {
    "papermill": {
     "duration": 0.016675,
     "end_time": "2023-02-27T12:45:39.842554",
     "exception": false,
     "start_time": "2023-02-27T12:45:39.825879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "The resulting value is the Gini coefficient, which ranges from 0 to 1. A Gini coefficient of 0 indicates a random classifier, while a Gini coefficient of 1 indicates a perfect classifier.\n",
    "\n",
    "The Gini coefficient is similar to the area under the receiver operating characteristic curve (ROC AUC), which is another commonly used evaluation metric for binary classification models. However, the Gini coefficient is often preferred in cases where the positive class is rare, as it is more sensitive to the performance of the model on the positive class.\n",
    "\n",
    "The major disadvantage of the Gini coefficient comes from the fact that it is an ordinal metric, i.e., it captures the order of values while ignoring the distance between them. This characteristic of the Gini coefficient can sometimes mask poor model performances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9423ba0b",
   "metadata": {
    "papermill": {
     "duration": 0.016374,
     "end_time": "2023-02-27T12:45:39.875521",
     "exception": false,
     "start_time": "2023-02-27T12:45:39.859147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding:20px;color:white;margin:0;font-size:24px;text-align:left;display:fill;border-radius:5px;background-color:#3A578A;overflow:hidden\">Work In Progress</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c6029",
   "metadata": {
    "papermill": {
     "duration": 0.016219,
     "end_time": "2023-02-27T12:45:39.908252",
     "exception": false,
     "start_time": "2023-02-27T12:45:39.892033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 274.411485,
   "end_time": "2023-02-27T12:45:41.151046",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-27T12:41:06.739561",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
